# -*- coding: utf-8 -*-
import os, glob, io, base64, re
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import arabic_reshaper
from bidi.algorithm import get_display


# ========== (Ø¥Ø¶Ø§ÙØ© Ø¬Ø¯ÙŠØ¯Ø©) Ø³Ùƒikit-learn Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù„Ù„ØªÙ†Ø¨Ø¤ ==========
_SK_OK = True
try:
    from sklearn.linear_model import LinearRegression
except Exception:
    _SK_OK = False
# ============================================================

# =============== Ø¥Ø¹Ø¯Ø§Ø¯ Ø¹Ø§Ù… + Ø´Ø¹Ø§Ø± ===============
APP_DIR = os.path.dirname(os.path.abspath(__file__))
ASSETS_DIR = os.path.join(APP_DIR, "assets")
LOGO_DIR = ASSETS_DIR
LOGO_FILE_CANDIDATES = ["Aljeri-logo.png.png","logo.jpg","logo.jpeg","logo.svg"]

def read_logo_bytes():
    if os.path.isdir(LOGO_DIR):
        for name in LOGO_FILE_CANDIDATES:
            p = os.path.join(LOGO_DIR, name)
            if os.path.isfile(p):
                with open(p, "rb") as f:
                    return f.read()
    if os.path.isfile(LOGO_DIR):
        with open(LOGO_DIR, "rb") as f:
            return f.read()
    return None

logo_bytes = read_logo_bytes()

# Ø¯Ø§Ù„Ø© Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø³Ø§Ø± Ø§Ù„Ø®Ø· Ø§Ù„Ø¹Ø±Ø¨ÙŠ
def get_arabic_font_path():
    """Ø¥Ø±Ø¬Ø§Ø¹ Ù…Ø³Ø§Ø± Ø§Ù„Ø®Ø· Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹ - ÙŠØ¨Ø­Ø« ÙÙŠ Ø¹Ø¯Ø© Ù…Ø³Ø§Ø±Ø§Øª"""
    # Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© Ù„Ù„Ø®Ø·
    possible_paths = [
        os.path.join(ASSETS_DIR, "fonts", "NotoNaskhArabic-Regular.ttf"),
        os.path.join(APP_DIR, "assets", "fonts", "NotoNaskhArabic-Regular.ttf"),
        os.path.join(os.path.dirname(os.path.abspath(__file__)), "assets", "fonts", "NotoNaskhArabic-Regular.ttf"),
    ]
    
    # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
    for font_path in possible_paths:
        try:
            if os.path.isfile(font_path):
                return os.path.abspath(font_path)
        except Exception:
            continue
    
    return None

arabic_font_path = get_arabic_font_path()

st.set_page_config(page_title="ØªÙ‚Ø±ÙŠØ± Ù‚Ø³Ù… Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ 2025", page_icon="ğŸ“", layout="wide")

if "figures" not in st.session_state:
    st.session_state["figures"] = {}
figures = st.session_state["figures"]


DARK_GLASS_CSS = """
<style>
html, body, [data-testid="stAppViewContainer"], .block-container { direction: rtl; }
[data-testid="stAppViewContainer"] {
  background: radial-gradient(1200px 800px at 0% 0%, rgba(40,45,60,0.55) 0%, rgba(15,18,25,0.95) 60%),
              radial-gradient(1000px 700px at 100% 0%, rgba(30,35,50,0.55) 0%, rgba(15,18,25,0.95) 60%);
  backdrop-filter: blur(18px);
}
.block-container { padding-top: 1.2rem; max-width: 1400px; }
.glass {
  background: linear-gradient(180deg, rgba(255,255,255,0.09), rgba(255,255,255,0.03));
  border: 1px solid rgba(255,255,255,0.12);
  box-shadow: 0 10px 30px rgba(0,0,0,0.35);
  backdrop-filter: blur(18px);
  border-radius: 18px; padding: 1.1rem 1.2rem;
}
h1, h2, h3, h4, h5 { color: #ECF2FF !important; letter-spacing: .3px; }
body, p, div, label, span { color: #E3E9F5 !important; }
.header-flex { display:flex; align-items:center; justify-content:space-between; padding:.8rem 1rem; margin-bottom:.6rem; }
.header-left { display:flex; gap:.75rem; align-items:center; flex-direction:row-reverse; }
.logo-box {
  width: 84px; height: 84px; border-radius: 18px; overflow:hidden;
  background:linear-gradient(145deg,#0b1222,#0f172a);
  display:flex; align-items:center; justify-content:center;
  box-shadow:0 12px 24px rgba(0,0,0,0.5), inset 0 1px 0 rgba(255,255,255,0.06);
}
.logo-box img { width:100%; height:100%; object-fit:contain; }
.kpi {
  position: relative; border-radius: 18px; padding: 1rem; text-align: center; min-height: 150px;
  display:flex; flex-direction:column; justify-content:center;
  background: linear-gradient(180deg, rgba(255,255,255,0.08), rgba(255,255,255,0.03));
  border: 1px solid rgba(255,255,255,0.14);
  box-shadow: 0 18px 40px rgba(0,0,0,0.35), inset 0 1px 0 rgba(255,255,255,0.05);
}
.kpi .title { color:#9FB3C8; font-size:.95rem; margin-bottom:.35rem; }
.kpi .value { font-size:2rem; font-weight:800; color:#F5FAFF; line-height:1.15; }
.badge {
  display:inline-block; padding:.25rem .55rem; border-radius:999px; font-size:.85rem;
  background: rgba(255,255,255,0.08); border: 1px solid rgba(255,255,255,0.16); color: #cfe4ff;
}
hr { border:none; height:1px; background:rgba(255,255,255,0.12); margin:12px 0; }
</style>
"""
st.markdown(DARK_GLASS_CSS, unsafe_allow_html=True)

if logo_bytes:
    b64 = base64.b64encode(logo_bytes).decode("utf-8")
    logo_img_html = f'<div class="logo-box"><img src="data:image/png;base64,{b64}" alt="logo"/></div>'
else:
    logo_img_html = '<div class="logo-box"><span style="font-size:26px;">ğŸ“</span></div>'

st.markdown(
    f"""
    <div class="glass header-flex">
      <div class="header-left">
        <div>
          <h2 style="margin:0;">ØªÙ‚Ø±ÙŠØ± Ù‚Ø³Ù… Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ 2025</h2>
          <div style="color:#9FB3C8;margin-top:-4px;font-size:.95rem;">Ø¹Ø±Ø¶ ØªÙØ§Ø¹Ù„ÙŠ Ù„Ù„Ù…Ø¤Ø´Ø±Ø§Øª ÙˆØ§Ù„Ø±Ø³ÙˆÙ… ÙˆØ§Ù„Ø®Ø±ÙŠØ·Ø©</div>
        </div>
      </div>
      {logo_img_html}
    </div>
    """,
    unsafe_allow_html=True
)

# =============== Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø´Ù‡ÙˆØ± ÙˆØªØ±Ø¬ÙÙ…Ø§Øª Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ ===============
MONTH_ORDER = ["Aug", "Sep", "Oct", "Nov"]  # Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ø© Ø§Ù„Ø¢Ù†
MONTH_INDEX = {m:i for i,m in enumerate(MONTH_ORDER)}
MONTH_MAP = {"Jan":1,"Feb":2,"Mar":3,"Apr":4,"May":5,"Jun":6,"Jul":7,"Aug":8,"Sep":9,"Oct":10,"Nov":11,"Dec":12}
INV_MONTH_MAP = {v:k for k,v in MONTH_MAP.items()}

PROVIDER_AR = {
    "Aljauhara": "Ø§Ù„Ø¬ÙˆÙ‡Ø±Ø©",
    "Reem": "Ø±ÙŠÙ…",
    "Ahad": "Ø¹Ù‡Ø¯",
    "Shouq": "Ø´ÙˆÙ‚",
    "Abdulmageed": "Ø¹Ø¨Ø¯Ø§Ù„Ù…Ø¬ÙŠØ¯",
    "Abdulkareem": "Ø¹Ø¨Ø¯Ø§Ù„ÙƒØ±ÙŠÙ…",
}
def provider_to_ar(name: str) -> str:
    return PROVIDER_AR.get(name, name)

def ar_to_provider(ar_name: str) -> str:
    rev = {v:k for k,v in PROVIDER_AR.items()}
    return rev.get(ar_name, ar_name)

# Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„ØªØ±Ø¬Ù…Ø© Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø´Ù‡Ø±
MONTH_AR = {"Aug": "Ø£ØºØ³Ø·Ø³", "Sep": "Ø³Ø¨ØªÙ…Ø¨Ø±", "Oct": "Ø£ÙƒØªÙˆØ¨Ø±", "Nov": "Ù†ÙˆÙÙ…Ø¨Ø±"}
def month_to_ar(month: str) -> str:
    return MONTH_AR.get(month, month)

# --- ØªÙˆØ­ÙŠØ¯ Ù‚ÙŠÙ… Ø§Ù„Ø´Ù‡Ø± (Oct/October/Ø£ÙƒØªÙˆØ¨Ø±â€¦ -> Oct) ---
MONTH_SYNONYMS = {
    "aug": "Aug", "aug.": "Aug", "august": "Aug", "Ø£ØºØ³Ø·Ø³": "Aug", "Ø§ØºØ³Ø·Ø³": "Aug",
    "sep": "Sep", "sep.": "Sep", "september": "Sep", "Ø³Ø¨ØªÙ…Ø¨Ø±": "Sep",
    "oct": "Oct", "oct.": "Oct", "october": "Oct", "Ø£ÙƒØªÙˆØ¨Ø±": "Oct", "Ø§ÙƒØªÙˆØ¨Ø±": "Oct",
    "nov": "Nov", "nov.": "Nov", "november": "Nov", "Ù†ÙˆÙÙ…Ø¨Ø±": "Nov",
}
def normalize_month_value(val, dt):
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ© Ø£Ùˆ NaN
    if pd.isna(val) or val is None:
        if pd.notna(dt):
            mnum = int(dt.month)
            canon = INV_MONTH_MAP.get(mnum)
            return canon if canon and canon in MONTH_ORDER else np.nan
        return np.nan
    
    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù†Øµ ÙˆØªÙ†Ø¸ÙŠÙ
    s = str(val).strip()
    if not s or s.lower() in ['nan', 'none', '']:
        if pd.notna(dt):
            mnum = int(dt.month)
            canon = INV_MONTH_MAP.get(mnum)
            return canon if canon and canon in MONTH_ORDER else np.nan
        return np.nan
    
    # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø±Ø§Ø¯ÙØ§Øª (case-insensitive)
    s_lower = s.lower()
    if s_lower in MONTH_SYNONYMS:
        canon = MONTH_SYNONYMS[s_lower]
        return canon if canon in MONTH_ORDER else np.nan
    
    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø¹ Ø£ÙˆÙ„ 3 Ø£Ø­Ø±Ù
    if len(s) >= 3:
        s_3 = s[:3].title()
        if s_3 in MONTH_MAP:
            canon = s_3
            return canon if canon in MONTH_ORDER else np.nan
    
    # Ø¥Ø°Ø§ ÙØ´Ù„ ÙƒÙ„ Ø´ÙŠØ¡ ÙˆÙ„ÙƒÙ† Ø§Ù„ØªØ§Ø±ÙŠØ® Ù…ÙˆØ¬ÙˆØ¯ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªØ§Ø±ÙŠØ®
    if pd.notna(dt):
        mnum = int(dt.month)
        canon = INV_MONTH_MAP.get(mnum)
        return canon if canon and canon in MONTH_ORDER else np.nan
    
    return np.nan

# =============== ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ===============
def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        return df
    df = df.rename(columns=lambda c: str(c).strip())
    mapping = {
        "Ø§Ù„ØªØ§Ø±ÙŠØ® ": "Ø§Ù„ØªØ§Ø±ÙŠØ®",
        "Date": "Ø§Ù„ØªØ§Ø±ÙŠØ®", "date": "Ø§Ù„ØªØ§Ø±ÙŠØ®",
        "Ø§Ù„Ù…Ù†Ø·Ù‚Ù‡": "Ø§Ù„Ù…Ù†Ø·Ù‚Ø©",
        "Ø§Ù„Ù…Ø¯ÙŠÙ†Ù‡ ": "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©", "Ø§Ù„Ù…Ø¯ÙŠÙ†Ù‡": "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©",
        "Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©": "Ø§Ù„Ø®Ø¯Ù…Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ù‡",
        "Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ù‡": "Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø©",
        "Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„ ": "Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„",
        "Ø±Ù‚Ù… Ø§Ù„Ø¬ÙˆØ§Ù„ ": "Ø±Ù‚Ù… Ø§Ù„Ø¬ÙˆØ§Ù„",
    }
    df = df.rename(columns={c: mapping.get(c, c) for c in df.columns})
    return df

# =============== Ø¨Ù†Ø§Ø¡ Ø§Ù„ØªØ§Ø±ÙŠØ® Ù…Ù† (Ø§Ù„Ø´Ù‡Ø± + Ø§Ù„ÙŠÙˆÙ…) ===============
def build_date_from_month_day(row: pd.Series):
    # Ù…Ø­Ø§ÙˆÙ„Ø© Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØªØ§Ø±ÙŠØ® Ù…Ø¨Ø§Ø´Ø±Ø© Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹ Ø¨ØªÙ†Ø³ÙŠÙ‚ ØªØ§Ø±ÙŠØ®
    raw_date = row.get("Ø§Ù„ØªØ§Ø±ÙŠØ®","")
    if pd.notna(raw_date) and raw_date != "":
        raw_str = str(raw_date).strip()
        if "/" in raw_str or "-" in raw_str:
            dt = pd.to_datetime(raw_str, dayfirst=True, errors="coerce")
            if pd.notna(dt):
                return dt
    
    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ù†Ø§Ø¡ Ø§Ù„ØªØ§Ø±ÙŠØ® Ù…Ù† Ø§Ù„Ø´Ù‡Ø± ÙˆØ§Ù„ÙŠÙˆÙ…
    month_val = row.get("Ø§Ù„Ø´Ù‡Ø±","")
    day_val = row.get("Ø§Ù„ØªØ§Ø±ÙŠØ®","")
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø´Ù‡Ø±
    month_str = ""
    if pd.notna(month_val) and month_val != "":
        month_str = str(month_val).strip()
    
    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø´Ù‡Ø± ÙÙŠ MONTH_MAP Ù…Ø¨Ø§Ø´Ø±Ø© (Ù…Ø«Ù„ "Nov", "Oct")
    if month_str in MONTH_MAP:
        try:
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙŠÙˆÙ… Ù…Ù† Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªØ§Ø±ÙŠØ®
            day_str = str(day_val).strip() if pd.notna(day_val) and day_val != "" else "1"
            # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ ØªÙ†Ø³ÙŠÙ‚Ø§Øª ØªØ§Ø±ÙŠØ®ÙŠØ©
            if "/" in day_str:
                day_str = day_str.split("/")[0].strip()
            elif "-" in day_str:
                day_str = day_str.split("-")[0].strip()
            day = int(float(day_str)) if day_str and day_str.replace(".","").isdigit() else 1
            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„ÙŠÙˆÙ… ØµØ­ÙŠØ­ (1-31)
            day = max(1, min(31, day))
            return pd.Timestamp(year=2025, month=MONTH_MAP[month_str], day=day)
        except (ValueError, TypeError) as e:
            # Ø¥Ø°Ø§ ÙØ´Ù„ØŒ Ù†Ø±Ø¬Ø¹ NaT
            return pd.NaT
    
    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… normalize_month_value Ù„Ù„Ø´Ù‡Ø±
    if month_str:
        month_lower = month_str.lower()
        if month_lower in MONTH_SYNONYMS:
            canon_month = MONTH_SYNONYMS[month_lower]
            if canon_month in MONTH_MAP:
                try:
                    day_str = str(day_val).strip() if pd.notna(day_val) and day_val != "" else "1"
                    if "/" in day_str:
                        day_str = day_str.split("/")[0].strip()
                    elif "-" in day_str:
                        day_str = day_str.split("-")[0].strip()
                    day = int(float(day_str)) if day_str and day_str.replace(".","").isdigit() else 1
                    day = max(1, min(31, day))
                    return pd.Timestamp(year=2025, month=MONTH_MAP[canon_month], day=day)
                except (ValueError, TypeError):
                    return pd.NaT
    
    return pd.NaT

# =============== Ø£Ø³Ø§Ø¨ÙŠØ¹ Ø§Ù„Ø£Ø­Ø¯â†’Ø§Ù„Ø³Ø¨Øª ÙˆØªØ±Ù‚ÙŠÙ…Ù‡Ø§ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø´Ù‡Ø± ===============
def add_week_columns(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty or "Ø§Ù„ØªØ§Ø±ÙŠØ®/Date" not in df.columns:
        df["ISO_Year"]=np.nan; df["ISO_Week"]=np.nan
        df["WeekStart"]=pd.NaT; df["WeekEnd"]=pd.NaT
        df["Ø±Ù‚Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"]=np.nan; df["ÙˆØ³Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"]=""
        return df

    d = df.copy()
    wd = d["Ø§Ù„ØªØ§Ø±ÙŠØ®/Date"].dt.weekday              # Monday=0..Sunday=6
    start_offset = (wd + 1) % 7                     # Ù„Ù„Ø£Ø­Ø¯
    d["WeekStart"] = d["Ø§Ù„ØªØ§Ø±ÙŠØ®/Date"] - pd.to_timedelta(start_offset, unit="D")
    d["WeekEnd"]   = d["WeekStart"] + pd.to_timedelta(6, unit="D")  # Ø§Ù„Ø³Ø¨Øª (Ø£Ø³Ø¨ÙˆØ¹ ÙƒØ§Ù…Ù„)

    d["ISO_Year"]  = d["WeekStart"].dt.isocalendar().year
    d["ISO_Week"]  = d["WeekStart"].dt.isocalendar().week

    if "Ø§Ù„Ø´Ù‡Ø±" in d.columns:
        # Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„ÙØ¹Ù„ÙŠ (WeekStart) ÙƒÙ€ identifier Ù…ÙˆØ­Ù‘Ø¯ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† ØªØ±Ù‚ÙŠÙ… Ù…Ù†ÙØµÙ„ Ù„ÙƒÙ„ Ù…Ù‚Ø¯Ù… Ø®Ø¯Ù…Ø©
        # Ù‡Ø°Ø§ ÙŠØ¶Ù…Ù† Ø£Ù† Ù†ÙØ³ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ù„Ù‡ Ù†ÙØ³ Ø§Ù„ÙˆØ³Ù… ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª
        def label_week(ws, we, month):
            if pd.isna(ws) or pd.isna(we):
                return ""
            month_name_ar = MONTH_AR.get(month, month)
            # Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„ÙØ¹Ù„ÙŠ Ù„Ù„Ø£Ø³Ø¨ÙˆØ¹ ÙƒÙ€ identifier
            return f"{month_name_ar} - Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ ({ws.strftime('%d/%m')}â€“{we.strftime('%d/%m')})"
        
        d["ÙˆØ³Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"] = [
            label_week(ws, we, m) 
            for ws, we, m in zip(d["WeekStart"], d["WeekEnd"], d["Ø§Ù„Ø´Ù‡Ø±"])
        ]
        
        # Ø±Ù‚Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ ÙŠÙØ­Ø³Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ±ØªÙŠØ¨ WeekStart Ø¯Ø§Ø®Ù„ ÙƒÙ„ Ø´Ù‡Ø±
        # Ù„ÙƒÙ† Ø§Ù„ÙˆØ³Ù… ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„ÙØ¹Ù„ÙŠ ÙÙ‚Ø·
        def rank_weeks_in_month(g):
            mnum = MONTH_MAP.get(g.name, None)
            if not mnum:
                gg = g.copy()
                gg["Ø±Ù‚Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"] = np.nan
                return gg
            
            # Ø¬Ù…Ø¹ ÙƒÙ„ Ø§Ù„Ø£Ø³Ø§Ø¨ÙŠØ¹ Ø§Ù„ÙØ±ÙŠØ¯Ø© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø´Ù‡Ø± (Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ WeekStart)
            weeks = (
                g.dropna(subset=["WeekStart"])
                [["WeekStart"]]
                .drop_duplicates()
                .sort_values("WeekStart")
                .reset_index(drop=True)
            )
            weeks["rank"] = range(1, len(weeks) + 1)
            rank_map = {ws: int(r) for ws, r in zip(weeks["WeekStart"], weeks["rank"])}
            
            gg = g.copy()
            gg["Ø±Ù‚Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"] = gg["WeekStart"].map(rank_map).astype("float")
            return gg
        
        d = d.groupby("Ø§Ù„Ø´Ù‡Ø±", group_keys=False).apply(rank_weeks_in_month)
    else:
        d["Ø±Ù‚Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"] = np.nan
        d["ÙˆØ³Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"] = ""

    return d

# =============== ØªØ­Ù…ÙŠÙ„ ÙƒÙ„ CSV Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ===============
@st.cache_data(show_spinner=True, ttl=10)  # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù€ cache ÙƒÙ„ 10 Ø«ÙˆØ§Ù†ÙŠ
def load_all(folder="data"):
    files = sorted(glob.glob(os.path.join(folder, "*.csv")))
    datasets = {}
    for path in files:
        provider = os.path.splitext(os.path.basename(path))[0].strip()

        df = None
        err_msg = None
        for attempt in range(2):
            try:
                df = pd.read_csv(
                    path,
                    encoding="utf-8-sig",
                    engine="python",
                    on_bad_lines="skip",
                    sep=",",
                    quotechar='"',
                    skipinitialspace=True
                )
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ù ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ header ØµØ­ÙŠØ­
                # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙƒÙ„Ù‡Ø§ Ø£Ø±Ù‚Ø§Ù… Ø£Ùˆ ÙØ§Ø±ØºØ©ØŒ ÙØ§Ù„Ù…Ù„Ù Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ header
                first_row_values = df.iloc[0].values if not df.empty else []
                col_names = df.columns.tolist()
                
                # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙƒÙ„Ù‡Ø§ Ø£Ø±Ù‚Ø§Ù… (0, 1, 2, ...) Ø£Ùˆ ÙƒØ§Ù†Øª Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ ØªØ¨Ø¯Ùˆ ÙƒØ¨ÙŠØ§Ù†Ø§Øª ÙˆÙ„ÙŠØ³Øª header
                is_header_missing = (
                    all(str(c).isdigit() for c in col_names) or
                    (len(col_names) > 0 and len(df) > 0 and 
                     any(str(first_row_values[i]).strip() not in col_names[i] for i in range(min(len(col_names), len(first_row_values))))
                     and col_names[0] not in ["Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„", "Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„ ", "name", "Name"])
                )
                
                # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ù†Ø§Ùƒ header ØµØ­ÙŠØ­ØŒ Ù†Ù‚Ø±Ø£ Ø§Ù„Ù…Ù„Ù Ø¨Ø¯ÙˆÙ† header ÙˆÙ†Ø­Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙŠØ¯ÙˆÙŠØ§Ù‹
                if is_header_missing and len(df.columns) >= 10:
                    # Ù†Ù‚Ø±Ø£ Ø§Ù„Ù…Ù„Ù Ø¨Ø¯ÙˆÙ† header
                    df = pd.read_csv(
                        path,
                        encoding="utf-8-sig",
                        engine="python",
                        on_bad_lines="skip",
                        sep=",",
                        quotechar='"',
                        skipinitialspace=True,
                        header=None
                    )
                    # Ù†Ø­Ø¯Ø¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©
                    expected_cols = ["Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„", "Ø±Ù‚Ù… Ø§Ù„Ø¬ÙˆØ§Ù„", "Ø§Ù„Ù…Ù†Ø·Ù‚Ø©", "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©", "Ø§Ù„Ø´Ø±ÙƒØ©", 
                                   "Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø©", "Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø©", "Ø§Ù„Ø®Ø¯Ù…Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ù‡", "Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„", 
                                   "Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª", "Ø§Ù„Ø´Ù‡Ø±", "Ø§Ù„ØªØ§Ø±ÙŠØ®"]
                    # Ù†Ø³ØªØ®Ø¯Ù… Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© Ø­Ø³Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ¹Ù„ÙŠØ©
                    if len(df.columns) >= len(expected_cols):
                        df.columns = expected_cols[:len(df.columns)]
                    elif len(df.columns) == 12:
                        df.columns = expected_cols
                    else:
                        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…Ø®ØªÙ„ÙØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
                        df.columns = expected_cols[:len(df.columns)] + [f"Ø¹Ù…ÙˆØ¯_{i}" for i in range(len(expected_cols), len(df.columns))]
                
                break
            except Exception as e:
                err_msg = str(e)

        if df is None:
            st.error(f"ØªØ¹Ø°Ù‘Ø± Ù‚Ø±Ø§Ø¡Ø© {os.path.basename(path)} â€” {err_msg}")
            continue

        if df.empty:
            st.warning(f"Ø§Ù„Ù…Ù„Ù {os.path.basename(path)} ÙØ§Ø±Øº Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ.")
            continue

        # Ù†Ø¸Ø§ÙØ© Ø£Ø³Ø§Ø³ÙŠØ©
        df.dropna(how="all", inplace=True)
        df = normalize_columns(df)

        # ØªÙ†Ø¸ÙŠÙ ÙˆØªÙˆØ­ÙŠØ¯ Ø¹Ù…ÙˆØ¯ Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„: Ø­Ø°Ù Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø© ÙˆØ§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙØ¹Ù„ÙŠØ©
        if "Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„" in df.columns:
            df["Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„"] = df["Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„"].astype(str).str.strip()

        # ØªØ§Ø±ÙŠØ® Ù…ÙˆØ­Ù‘Ø¯
        df["Ø§Ù„ØªØ§Ø±ÙŠØ®/Date"] = pd.to_datetime(df.apply(build_date_from_month_day, axis=1), errors="coerce")

        # --- Ø§Ù„Ø´Ù‡Ø±: ØªÙˆØ­ÙŠØ¯ Ù‚ÙˆÙŠ Ù‚Ø¨Ù„ Ø§Ù„Ø­ØµØ± ---
        if "Ø§Ù„Ø´Ù‡Ø±" not in df.columns:
            # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø´Ù‡Ø±ØŒ Ù†Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø±Ø§Ø¬Ù‡ Ù…Ù† Ø§Ù„ØªØ§Ø±ÙŠØ®
            df["Ø§Ù„Ø´Ù‡Ø±"] = df["Ø§Ù„ØªØ§Ø±ÙŠØ®/Date"].dt.month.map(INV_MONTH_MAP).where(
                df["Ø§Ù„ØªØ§Ø±ÙŠØ®/Date"].dt.month.map(INV_MONTH_MAP).isin(MONTH_ORDER), np.nan
            )
        else:
            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙˆØ­ÙŠØ¯ Ù…Ø¹ Ø§Ù„ØªØ§Ø±ÙŠØ® (Ù…Ø¹Ø§Ù„Ø¬Ø© ØµØ­ÙŠØ­Ø© Ù„Ù„Ù‚ÙŠÙ… NaN)
            month_series = df["Ø§Ù„Ø´Ù‡Ø±"].copy()
            date_series = df["Ø§Ù„ØªØ§Ø±ÙŠØ®/Date"]
            df["Ø§Ù„Ø´Ù‡Ø±"] = [
                normalize_month_value(
                    month_series.iloc[i] if pd.notna(month_series.iloc[i]) else None,
                    date_series.iloc[i] if pd.notna(date_series.iloc[i]) else pd.NaT
                )
                for i in range(len(df))
            ]
            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù‚ÙŠÙ… ÙÙŠ MONTH_ORDER ÙÙ‚Ø·
            df["Ø§Ù„Ø´Ù‡Ø±"] = df["Ø§Ù„Ø´Ù‡Ø±"].where(df["Ø§Ù„Ø´Ù‡Ø±"].isin(MONTH_ORDER), np.nan)

        # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù†ØµÙˆØµ (Ø¨Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ø°ÙŠ ØªÙ… ØªÙˆØ­ÙŠØ¯Ù‡ Ø¨Ø§Ù„ÙØ¹Ù„)
        text_cols = ["Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„","Ø±Ù‚Ù… Ø§Ù„Ø¬ÙˆØ§Ù„","Ø§Ù„Ù…Ù†Ø·Ù‚Ø©","Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©","Ø§Ù„Ø´Ø±ÙƒØ©","Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø©","Ø§Ù„Ø®Ø¯Ù…Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ù‡"]
        for col in text_cols:
            if col in df.columns:
                df[col] = df[col].astype(str).str.strip()
        # Ø§Ù„Ø´Ù‡Ø±: Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ù‡ Ù†Øµ (Ù„ÙƒÙ† Ù†Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ NaN ÙƒÙ‚ÙŠÙ…Ø© NaN ÙˆÙ„ÙŠØ³ Ù†Øµ "nan")
        # Ù„Ø§ Ù†Ø­ØªØ§Ø¬ Ù„ØªØ­ÙˆÙŠÙ„Ù‡ Ù„Ø£Ù† normalize_month_value ÙŠØ¹Ø·ÙŠÙ†Ø§ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„ØµØ­ÙŠØ­Ø© Ø¨Ø§Ù„ÙØ¹Ù„

        # Ø¨Ù†Ø§Ø¡ Ø£Ø³Ø§Ø¨ÙŠØ¹ Ø§Ù„Ø¹Ù…Ù„
        df = add_week_columns(df)

        # Ù…ØµØ¯Ø± Ø§Ù„Ù…Ù„Ù
        df["Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (Ù…Ù„Ù)"] = provider
        datasets[provider] = df

        if err_msg is not None:
            st.warning(f"ØªÙ… ØªØ®Ø·Ù‘ÙŠ Ø£Ø³Ø·Ø± ØªØ§Ù„ÙØ© ÙÙŠ {os.path.basename(path)} Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø¹Ù…Ù„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚.")

    if datasets:
        all_df = pd.concat(list(datasets.values()), ignore_index=True, sort=False)
        datasets["__ALL__"] = all_df

    return datasets

datasets = load_all()
if not datasets:
    st.error("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø£ÙŠ CSV Ø¯Ø§Ø®Ù„ data/. Ø£Ø¶ÙŠÙÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª Ø«Ù… Ø£Ø¹ÙŠØ¯ÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„.")
    st.stop()

# =============== Ø²Ø± ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ===============
col1, col2, col3 = st.columns([2, 1, 2])
with col2:
    if st.button("ğŸ”„ Ø­Ø¯Ù‘Ø« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", use_container_width=True, help="Ø§Ø¶ØºØ· Ù„Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª"):
        st.cache_data.clear()
        st.rerun()

# =============== Ø§Ù„Ù…Ø±Ø´Ù‘Ø­Ø§Øª ===============
providers = [k for k in datasets.keys() if k != "__ALL__"]
providers_ar = ["Ø§Ù„ÙƒÙ„"] + [provider_to_ar(p) for p in providers]

with st.form("main_filters"):
    c1, c2, c3 = st.columns([1.2, 1.2, 1.2])

    with c1:
        st.markdown('<div class="glass"><b>Ù…Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø®Ø¯Ù…Ø©</b>', unsafe_allow_html=True)
        provider_choice_ar = st.selectbox("Ø§Ø®ØªØ±", providers_ar, index=0)
        st.markdown('</div>', unsafe_allow_html=True)

    # Ù†Ø·Ø§Ù‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø©
    if provider_choice_ar == "Ø§Ù„ÙƒÙ„":
        provider_key = "__ALL__"
        df_scope = datasets["__ALL__"].copy()
    else:
        provider_key = ar_to_provider(provider_choice_ar)
        df_scope = datasets.get(provider_key, pd.DataFrame()).copy()

    with c2:
        st.markdown('<div class="glass"><b>ØªØµÙÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø´Ù‡Ø±</b>', unsafe_allow_html=True)
        months_av = []
        if "Ø§Ù„Ø´Ù‡Ø±" in df_scope.columns:
            months_av = [m for m in MONTH_ORDER if m in df_scope["Ø§Ù„Ø´Ù‡Ø±"].dropna().unique().tolist()]
        # Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
        month_options = ["Ø§Ù„ÙƒÙ„"] + [f"{month_to_ar(m)} ({m})" for m in months_av]
        month_choice_display = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø´Ù‡Ø±", month_options, index=0)
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ù…Ø² Ø§Ù„Ø´Ù‡Ø± Ù…Ù† Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±
        if month_choice_display == "Ø§Ù„ÙƒÙ„":
            month_choice = "Ø§Ù„ÙƒÙ„"
        else:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ù…Ø² Ø§Ù„Ø´Ù‡Ø± Ù…Ù† Ø§Ù„Ù†Øµ (Ù…Ø«Ù„ "Ø£ØºØ³Ø·Ø³ (Aug)" -> "Aug")
            month_choice = month_choice_display.split("(")[-1].replace(")", "").strip() if "(" in month_choice_display else month_choice_display
        st.caption("ğŸ’¡ ÙƒÙ„ Ø´Ù‡Ø± Ù„Ù‡ Ø£Ø³Ø§Ø¨ÙŠØ¹ Ù…Ù†ÙØµÙ„Ø©. ÙŠÙÙØ¶Ù„ Ø§Ø®ØªÙŠØ§Ø± Ø´Ù‡Ø± Ø£ÙˆÙ„Ø§Ù‹ Ø«Ù… Ø§Ù„Ù†Ù‚Ø± Ø¹Ù„Ù‰ Ø²Ø± ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø±Ø´Ù‘Ø­Ø§Øª Ø«Ù… Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ù…Ù† Ù‚Ø§Ø¦Ù…Ø© Ø§Ø®ØªØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ù„ØªØµÙÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø¨ÙŠØ¹.")
        st.markdown('</div>', unsafe_allow_html=True)

    with c3:
        st.markdown('<div class="glass"><b>ØªØµÙÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹</b>', unsafe_allow_html=True)
        # Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ ÙŠØ¸Ù‡Ø± Ø¯Ø§Ø¦Ù…Ù‹Ø§: Ù†Ø¬Ù…Ø¹ Ø£Ø³Ø§Ø¨ÙŠØ¹ Ù†Ø·Ø§Ù‚ df_scope Ø«Ù… Ù†Ù‚ÙŠÙ‘Ø¯ Ø¥Ø°Ø§ ØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø´Ù‡Ø±
        week_options = ["Ø§Ù„ÙƒÙ„"]
        tmp = df_scope.copy()
        
        # Ø¥Ø°Ø§ ØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø´Ù‡Ø±ØŒ Ù†Ø¹Ø±Ø¶ Ø£Ø³Ø§Ø¨ÙŠØ¹ Ù‡Ø°Ø§ Ø§Ù„Ø´Ù‡Ø± ÙÙ‚Ø·
        if month_choice != "Ø§Ù„ÙƒÙ„":
            tmp = tmp[tmp["Ø§Ù„Ø´Ù‡Ø±"] == month_choice]
            month_name_ar = month_to_ar(month_choice)
            help_text = f"ğŸ“… ÙŠØªÙ… Ø¹Ø±Ø¶ Ø£Ø³Ø§Ø¨ÙŠØ¹ Ø´Ù‡Ø± {month_name_ar} ÙÙ‚Ø·. Ø§Ù„Ø£Ø±Ù‚Ø§Ù… (1ØŒ 2ØŒ 3...) ØªØ¨Ø¯Ø£ Ù…Ù† Ø¬Ø¯ÙŠØ¯ ÙÙŠ ÙƒÙ„ Ø´Ù‡Ø±."
        else:
            help_text = "ğŸ“… Ù…Ù„Ø§Ø­Ø¸Ø©: ÙƒÙ„ Ø´Ù‡Ø± Ù„Ù‡ Ø£Ø³Ø§Ø¨ÙŠØ¹ Ù…Ù†ÙØµÙ„Ø© ÙˆÙ…ÙØ±Ù‚Ù…Ø© Ø¨Ø´ÙƒÙ„ Ù…Ø³ØªÙ‚Ù„. ÙŠÙÙØ¶Ù„ Ø§Ø®ØªÙŠØ§Ø± Ø´Ù‡Ø± Ø£ÙˆÙ„Ø§Ù‹ Ù„ØªØ³Ù‡ÙŠÙ„ Ø§Ù„Ø¨Ø­Ø«."
        
        if "ÙˆØ³Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹" in tmp.columns and not tmp.empty:
            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø³Ø§Ø¨ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„ØªØ§Ø±ÙŠØ® (ØªØµØ§Ø¹Ø¯ÙŠ) - Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„ØµØ­ÙŠØ­
            uniq = (
                tmp.dropna(subset=["WeekStart","WeekEnd", "ÙˆØ³Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"])
                   .drop_duplicates(subset=["WeekStart"])
                   .sort_values("WeekStart", ascending=True)  # ØªØ±ØªÙŠØ¨ ØªØµØ§Ø¹Ø¯ÙŠ Ø­Ø³Ø¨ Ø§Ù„ØªØ§Ø±ÙŠØ®
            )
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø³Ø§Ø¨ÙŠØ¹ Ù…Ø±ØªØ¨Ø© Ø­Ø³Ø¨ Ø§Ù„ØªØ§Ø±ÙŠØ®
            week_options += uniq["ÙˆØ³Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"].tolist()
        
        week_choice = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹", week_options, index=0)
        st.caption(help_text)
        st.markdown('</div>', unsafe_allow_html=True)

    st.form_submit_button("ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø±Ø´Ù‘Ø­Ø§Øª âœ…")

# =============== ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØµÙÙŠØ© ===============
filtered = df_scope.copy()
if month_choice != "Ø§Ù„ÙƒÙ„":
    # Ù†ØªØ£ÙƒØ¯ Ù…Ù† ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù‚ÙŠÙ… Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©
    filtered = filtered[filtered["Ø§Ù„Ø´Ù‡Ø±"].astype(str).str.strip() == month_choice]
if week_choice != "Ø§Ù„ÙƒÙ„" and "ÙˆØ³Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹" in filtered.columns:
    filtered = filtered[filtered["ÙˆØ³Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"].astype(str).str.strip() == week_choice.strip()]

# =============== KPI + Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© ===============
total_calls = int(len(filtered))

def top_month_in_scope(df):
    if df.empty or "Ø§Ù„Ø´Ù‡Ø±" not in df.columns: return None, 0
    s = df["Ø§Ù„Ø´Ù‡Ø±"].value_counts().sort_values(ascending=False)
    return (s.index[0], int(s.iloc[0])) if len(s) else (None, 0)

def average_for_selection(df: pd.DataFrame, month_choice: str, week_choice: str):
    """
    - Ø¥Ø°Ø§ ØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø£Ø³Ø¨ÙˆØ¹: Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„ÙŠÙˆÙ…ÙŠ (Ø£Ø­Ø¯â€“Ø³Ø¨Øª).
    - Ø¥Ø°Ø§ ØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø´Ù‡Ø± ÙÙ‚Ø·: Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ Ø¯Ø§Ø®Ù„ Ù‡Ø°Ø§ Ø§Ù„Ø´Ù‡Ø±.
    - Ø¥Ø°Ø§ Ù„Ù… ÙŠÙØ­Ø¯Ù‘ÙØ¯ Ø´Ù‡Ø±/Ø£Ø³Ø¨ÙˆØ¹: Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø´Ù‡Ø±ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ø­Ø§Ù„ÙŠ.
    """
    if df.empty: return 0.0, "â€”"

    if week_choice != "Ø§Ù„ÙƒÙ„":
        if "WeekStart" not in df.columns or "WeekEnd" not in df.columns:
            return 0.0, "â€”"
        wdf = df[df["ÙˆØ³Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"] == week_choice].copy()
        if wdf.empty:
            return 0.0, "â€”"
        ws = pd.to_datetime(wdf["WeekStart"].iloc[0])
        we = pd.to_datetime(wdf["WeekEnd"].iloc[0])
        day_count = max(1, int((we - ws).days) + 1)  # Ø£Ø­Ø¯..Ø³Ø¨Øª (Ø£Ø³Ø¨ÙˆØ¹ ÙƒØ§Ù…Ù„)
        avg_per_day = len(wdf) / day_count
        return float(avg_per_day), f"Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„ÙŠÙˆÙ…ÙŠ â€” {ws.strftime('%b %d')}â€“{we.strftime('%b %d')}"

    if month_choice != "Ø§Ù„ÙƒÙ„":
        if "WeekStart" not in df.columns:
            return 0.0, "â€”"
        mdf = df[df["Ø§Ù„Ø´Ù‡Ø±"] == month_choice]
        if mdf.empty:
            return 0.0, "â€”"
        week_sizes = mdf.groupby("WeekStart").size()
        if len(week_sizes) == 0:
            return 0.0, "â€”"
        return float(week_sizes.mean()), f"Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ â€” Ø´Ù‡Ø± {month_choice}"

    if "Ø§Ù„Ø´Ù‡Ø±" in df.columns:
        month_sizes = df.groupby("Ø§Ù„Ø´Ù‡Ø±").size()
        if len(month_sizes)==0: return 0.0, "â€”"
        return float(month_sizes.mean()), "Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø´Ù‡Ø±ÙŠ â€” Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ø­Ø§Ù„ÙŠ"

    return 0.0, "â€”"

k1,k2,k3 = st.columns(3)
with k1:
    scope_title = "Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª" if provider_key=="__ALL__" else f"Ø§Ù„Ù…Ù„Ù: {provider_to_ar(provider_key)}"
    st.markdown(f"""<div class="kpi">
        <div class="title">Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª â€” {scope_title}</div>
        <div class="value">{total_calls}</div>
    </div>""", unsafe_allow_html=True)

m_name, m_val = top_month_in_scope(filtered if provider_key=="__ALL__" else datasets[provider_key])
with k2:
    st.markdown(f"""<div class="kpi">
        <div class="title">Ø£Ø¹Ù„Ù‰ Ø´Ù‡Ø± Ø¶Ù…Ù† Ø§Ù„Ù†Ø·Ø§Ù‚</div>
        <div class="value">{m_name or 'â€”'}</div>
        <div class="badge">Ø¹Ø¯Ø¯: {m_val}</div>
    </div>""", unsafe_allow_html=True)

avg_val, avg_label = average_for_selection(filtered, month_choice, week_choice)
with k3:
    st.markdown(f"""<div class="kpi">
        <div class="title">Ø§Ù„Ù…ØªÙˆØ³Ø· (Ø­Ø³Ø¨ Ø§Ù„ØªØµÙÙŠØ©)</div>
        <div class="value">{round(avg_val,2)}</div>
        <div class="badge">{avg_label}</div>
    </div>""", unsafe_allow_html=True)

# =============== (Ø¥Ø¶Ø§ÙØ© Ø¬Ø¯ÙŠØ¯Ø©) KPI Ù„ØªÙˆÙ‚Ù‘Ø¹ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ù‚Ø§Ø¯Ù… ===============
def calc_forecast(df_month_scope: pd.DataFrame):
    """
    ÙŠØ¨Ù†ÙŠ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø´Ù‡Ø±ÙŠ Ù…Ù† df_month_scope (Ù‚Ø¨Ù„ ØªØ±Ø´ÙŠØ­ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹)ØŒ
    Ø«Ù… ÙŠØ·Ø¨Ù‘Ù‚ LinearRegression Ø¥Ù† ØªÙˆÙØ±ØªØŒ Ø£Ùˆ ØªÙ‚Ø¯ÙŠØ± Ø¨Ø³ÙŠØ· Ø¥Ù† Ù„Ù… ØªØªÙˆÙØ±.
    """
    if df_month_scope is None or df_month_scope.empty or "Ø§Ù„Ø´Ù‡Ø±" not in df_month_scope.columns:
        return None, None, None

    month_totals = df_month_scope["Ø§Ù„Ø´Ù‡Ø±"].value_counts().reindex(MONTH_ORDER).dropna()
    if len(month_totals) < 1:
        return None, None, None

    x = np.array([MONTH_INDEX[m] for m in month_totals.index]).reshape(-1,1)
    y = month_totals.values.astype(float)

    # Ù†Ù…ÙˆØ°Ø¬ Ø®Ø·ÙŠ Ù…Ø¹ Ù†Ø·Ø§Ù‚ ØªÙ‚Ø±ÙŠØ¨ÙŠ
    if _SK_OK and len(y) >= 2:
        model = LinearRegression().fit(x, y)
        next_x_val = x[-1][0] + 1
        pred = float(model.predict(np.array([[next_x_val]]) )[0])
        resid = y - model.predict(x)
        sigma = float(np.std(resid)) if len(resid) > 1 else 0.0
        ci_low = max(0.0, pred - 1.96*sigma)
        ci_high = pred + 1.96*sigma
        return int(round(pred)), int(round(ci_low)), int(round(ci_high))

    # ØªÙ‚Ø¯ÙŠØ± Ù…Ø¨Ø³Ù‘Ø·
    if len(y) >= 2:
        growth = y[-1] - y[-2]
        pred = int(round(y[-1] + growth))
        return pred, None, None

    return None, None, None

# Ù†Ø­Ø³Ø¨ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ù†Ø·Ø§Ù‚ Ù…Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ø®ØªØ§Ø± (Ø¨Ø¯ÙˆÙ† ØªÙ‚ÙŠÙŠØ¯ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹Ø› Ù…Ø¹ Ø¨Ù‚Ø§Ø¡ ØªÙ‚ÙŠÙŠØ¯ Ø§Ù„Ø´Ù‡Ø± = Ø§Ù„ÙƒÙ„ Ù„ÙƒÙŠ ÙŠÙƒÙˆÙ† Ø´Ù‡Ø±ÙŠ Ø´Ø§Ù…Ù„)
df_for_forecast = df_scope.copy()
pred_next, pred_ci_low, pred_ci_high = calc_forecast(df_for_forecast)

# Ø¨Ø·Ø§Ù‚Ø© KPI Ù„Ù„ØªÙ†Ø¨Ø¤ (Ø³Ø·Ø± Ù…Ø³ØªÙ‚Ù„ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ù€KPI Ø§Ù„Ø­Ø§Ù„ÙŠØ©)
c_pred = st.columns(1)[0]
with c_pred:
    if pred_next is not None:
        ci_html = f'<div class="badge" style="margin-top:.35rem;">Ù†Ø·Ø§Ù‚ ØªÙ‚Ø±ÙŠØ¨ÙŠ: {pred_ci_low} â€“ {pred_ci_high}</div>' if (pred_ci_low is not None and pred_ci_high is not None) else ""
        st.markdown(f"""<div class="kpi" style="margin-top:.5rem;">
            <div class="title">ØªÙˆÙ‚Ù‘Ø¹ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ù‚Ø§Ø¯Ù… (Ø­Ø³Ø¨ Ù†Ø·Ø§Ù‚ Ù…Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ø®ØªØ§Ø±)</div>
            <div class="value">{pred_next}</div>
            {ci_html}
        </div>""", unsafe_allow_html=True)
    else:
        st.markdown(f"""<div class="kpi" style="margin-top:.5rem;">
            <div class="title">ØªÙˆÙ‚Ù‘Ø¹ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ù‚Ø§Ø¯Ù…</div>
            <div class="value">â€”</div>
            <div class="badge" style="margin-top:.35rem;">Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ©</div>
        </div>""", unsafe_allow_html=True)

st.markdown("<hr>", unsafe_allow_html=True)

# =============== Ø§Ù„Ø±Ø³ÙˆÙ… ===============
st.markdown('<div class="glass">', unsafe_allow_html=True)
st.markdown("### Ø§Ù„Ø±Ø³ÙˆÙ…")
c1, c2 = st.columns(2)
with c1:
    if "Ø§Ù„Ù…Ù†Ø·Ù‚Ø©" in filtered.columns and not filtered.empty:
        reg_counts = filtered["Ø§Ù„Ù…Ù†Ø·Ù‚Ø©"].value_counts().reset_index()
        reg_counts.columns = ["Ø§Ù„Ù…Ù†Ø·Ù‚Ø©","Ø§Ù„Ø¹Ø¯Ø¯"]
        fig_reg = px.bar(reg_counts, x="Ø§Ù„Ù…Ù†Ø·Ù‚Ø©", y="Ø§Ù„Ø¹Ø¯Ø¯", title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ù†Ø·Ù‚Ø©", text="Ø§Ù„Ø¹Ø¯Ø¯")
        fig_reg.update_traces(textposition="outside")
        fig_reg.update_layout(template="plotly_dark", margin=dict(t=60,b=40,l=20,r=20))
        st.plotly_chart(fig_reg, use_container_width=True)
    else:
        st.info("Ù„Ø§ ØªØªÙˆÙØ± Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù†Ø§Ø·Ù‚ Ø¶Ù…Ù† Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ù…Ø­Ø¯Ø¯.")
with c2:
    if "Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø©" in filtered.columns and not filtered.empty:
        tcounts = filtered["Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø©"].value_counts()
        fig_type = px.pie(names=tcounts.index, values=tcounts.values, title="Ù†Ø³Ø¨Ø© Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª", hole=0.35)
        fig_type.update_traces(textposition="inside", textinfo="percent+label")
        fig_type.update_layout(template="plotly_dark", margin=dict(t=60,b=40,l=20,r=20))
        st.plotly_chart(fig_type, use_container_width=True)
    else:
        st.info("Ù„Ø§ ØªØªÙˆÙØ± Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø¶Ù…Ù† Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ù…Ø­Ø¯Ø¯.")
if "Ø§Ù„Ø´Ø±ÙƒØ©" in filtered.columns and not filtered.empty:
    comp_counts = filtered["Ø§Ù„Ø´Ø±ÙƒØ©"].value_counts().reset_index()
    comp_counts.columns = ["Ø§Ù„Ø´Ø±ÙƒØ©","Ø§Ù„Ø¹Ø¯Ø¯"]
    fig_comp = px.bar(comp_counts, x="Ø§Ù„Ø´Ø±ÙƒØ©", y="Ø§Ù„Ø¹Ø¯Ø¯", title="Ø¹Ø¯Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø´Ø±ÙƒØ©", text="Ø§Ù„Ø¹Ø¯Ø¯")
    fig_comp.update_traces(textposition="outside")
    fig_comp.update_layout(template="plotly_dark", margin=dict(t=60,b=40,l=20,r=20))
    st.plotly_chart(fig_comp, use_container_width=True)
st.markdown('</div>', unsafe_allow_html=True)

# =============== ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø­Ø³Ø¨ Ù…Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (3 Pies) ===============
st.markdown('<div class="glass" style="margin-top:1rem;">', unsafe_allow_html=True)
st.markdown("### Ù†Ø³Ø¨Ø© Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø­Ø³Ø¨ Ù…Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø®Ø¯Ù…Ø©")

agent_col = "Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (Ù…Ù„Ù)" if "Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (Ù…Ù„Ù)" in df_scope.columns else ("Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø©" if "Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø©" in df_scope.columns else None)

if agent_col:
    col_total, col_oct, col_nov, col_week = st.columns(4)

    # --- 1) Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ (Ø­Ø³Ø¨ Ø§Ù„ØªØµÙÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ©) ---
    with col_total:
        if not filtered.empty:
            ac_total = filtered[agent_col].value_counts()
            if not ac_total.empty:
                names_total = ac_total.index.map(provider_to_ar) if agent_col == "Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (Ù…Ù„Ù)" else ac_total.index
                fig_agents_total = px.pie(
                    names=names_total, values=ac_total.values,
                    title="Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù†Ø³Ø¨Ø© Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª (Ø­Ø³Ø¨ Ø§Ù„ØªØµÙÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ©)", hole=0.35
                )
                fig_agents_total.update_traces(textposition="inside", textinfo="percent+label")
                fig_agents_total.update_layout(template="plotly_dark", margin=dict(t=60,b=40,l=20,r=20))
                st.plotly_chart(fig_agents_total, use_container_width=True)
            else:
                st.info("Ù„Ø§ ØªØªÙˆÙØ± Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù…Ù‚Ø¯Ù‘Ù…ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø© Ø¶Ù…Ù† Ø§Ù„ØªØµÙÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ©.")
        else:
            st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØµÙÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ©.")

    # --- 2) Ø´Ù‡Ø± Oct (ÙŠØ­ØªØ±Ù… Ø§Ø®ØªÙŠØ§Ø± Ù…Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø®Ø¯Ù…Ø©ØŒ Ù„Ø§ ÙŠØªØ£Ø«Ø± Ø¨Ù…Ø±Ø´Ø­ Ø§Ù„Ø´Ù‡Ø±/Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹) ---
    with col_oct:
        df_oct_scope = df_scope[df_scope["Ø§Ù„Ø´Ù‡Ø±"].astype(str).str.strip() == "Oct"].copy() if "Ø§Ù„Ø´Ù‡Ø±" in df_scope.columns else pd.DataFrame()
        if not df_oct_scope.empty:
            ac_oct = df_oct_scope[agent_col].value_counts()
            if not ac_oct.empty:
                names_oct = ac_oct.index.map(provider_to_ar) if agent_col == "Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (Ù…Ù„Ù)" else ac_oct.index
                fig_agents_oct = px.pie(
                    names=names_oct, values=ac_oct.values,
                    title="Ù†Ø³Ø¨Ø© Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª â€” Ø´Ù‡Ø± Ø£ÙƒØªÙˆØ¨Ø± (Ø¨Ù†ÙØ³ Ù†Ø·Ø§Ù‚ Ù…Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø®Ø¯Ù…Ø©)", hole=0.35
                )
                fig_agents_oct.update_traces(textposition="inside", textinfo="percent+label")
                fig_agents_oct.update_layout(template="plotly_dark", margin=dict(t=60,b=40,l=20,r=20))
                st.plotly_chart(fig_agents_oct, use_container_width=True)
            else:
                st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø´Ù‡Ø± Oct Ù„Ù†ÙØ³ Ù†Ø·Ø§Ù‚ Ù…Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø®Ø¯Ù…Ø©.")
        else:
            st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø³Ø¬Ù„Ø§Øª Ù„Ø´Ù‡Ø± Oct ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù†Ø·Ø§Ù‚.")

    # --- 3) Ø´Ù‡Ø± Nov (ÙŠØ­ØªØ±Ù… Ø§Ø®ØªÙŠØ§Ø± Ù…Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø®Ø¯Ù…Ø©ØŒ Ù„Ø§ ÙŠØªØ£Ø«Ø± Ø¨Ù…Ø±Ø´Ø­ Ø§Ù„Ø´Ù‡Ø±/Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹) ---
    with col_nov:
        df_nov_scope = df_scope[df_scope["Ø§Ù„Ø´Ù‡Ø±"].astype(str).str.strip() == "Nov"].copy() if "Ø§Ù„Ø´Ù‡Ø±" in df_scope.columns else pd.DataFrame()
        if not df_nov_scope.empty:
            ac_nov = df_nov_scope[agent_col].value_counts()
            if not ac_nov.empty:
                names_nov = ac_nov.index.map(provider_to_ar) if agent_col == "Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (Ù…Ù„Ù)" else ac_nov.index
                fig_agents_nov = px.pie(
                    names=names_nov, values=ac_nov.values,
                    title="Ù†Ø³Ø¨Ø© Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª â€” Ø´Ù‡Ø± Ù†ÙˆÙÙ…Ø¨Ø± (Ø¨Ù†ÙØ³ Ù†Ø·Ø§Ù‚ Ù…Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø®Ø¯Ù…Ø©)", hole=0.35
                )
                fig_agents_nov.update_traces(textposition="inside", textinfo="percent+label")
                fig_agents_nov.update_layout(template="plotly_dark", margin=dict(t=60,b=40,l=20,r=20))
                st.plotly_chart(fig_agents_nov, use_container_width=True)
            else:
                st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø´Ù‡Ø± Nov Ù„Ù†ÙØ³ Ù†Ø·Ø§Ù‚ Ù…Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø®Ø¯Ù…Ø©.")
        else:
            st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø³Ø¬Ù„Ø§Øª Ù„Ø´Ù‡Ø± Nov ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù†Ø·Ø§Ù‚.")

    # --- 4) Ø¢Ø®Ø± Ø£Ø³Ø¨ÙˆØ¹ (Ø£Ø­Ø¯Ø« WeekStart) Ø¶Ù…Ù† Ù†ÙØ³ Ù†Ø·Ø§Ù‚ Ù…Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø®Ø¯Ù…Ø© ---
    with col_week:
        if "WeekStart" in df_scope.columns and not df_scope.dropna(subset=["WeekStart"]).empty:
            latest_ws = pd.to_datetime(df_scope["WeekStart"]).max()
            df_last_week = df_scope[pd.to_datetime(df_scope["WeekStart"]) == latest_ws].copy()
            if not df_last_week.empty:
                ac_week = df_last_week[agent_col].value_counts()
                names_week = ac_week.index.map(provider_to_ar) if agent_col == "Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (Ù…Ù„Ù)" else ac_week.index
                # Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ø¶Ø­ Ù…Ø¹ Ù†Ø·Ø§Ù‚ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹
                we = pd.to_datetime(df_last_week["WeekEnd"].iloc[0]) if "WeekEnd" in df_last_week.columns else latest_ws + pd.Timedelta(days=6)
                week_title = f"Ù†Ø³Ø¨Ø© Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª â€” Ø¢Ø®Ø± Ø£Ø³Ø¨ÙˆØ¹ ({latest_ws.strftime('%b %d')}â€“{we.strftime('%b %d')})"
                fig_agents_week = px.pie(
                    names=names_week, values=ac_week.values,
                    title=week_title, hole=0.35
                )
                fig_agents_week.update_traces(textposition="inside", textinfo="percent+label")
                fig_agents_week.update_layout(template="plotly_dark", margin=dict(t=60,b=40,l=20,r=20))
                st.plotly_chart(fig_agents_week, use_container_width=True)
            else:
                st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø¢Ø®Ø± Ø£Ø³Ø¨ÙˆØ¹ Ø¯Ø§Ø®Ù„ Ù‡Ø°Ø§ Ø§Ù„Ù†Ø·Ø§Ù‚.")
        else:
            st.info("Ù„Ø§ ÙŠØªÙˆÙØ± Ø¹Ù…ÙˆØ¯ WeekStart/WeekEnd Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¢Ø®Ø± Ø£Ø³Ø¨ÙˆØ¹.")
else:
    st.info("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ Ù„Ù…Ù‚Ø¯Ù‘Ù…ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©.")
st.markdown('</div>', unsafe_allow_html=True)

# =============== (Ø¥Ø¶Ø§ÙØ© Ø¬Ø¯ÙŠØ¯Ø©) Visual: Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ù„Ù„Ø´Ù‡Ø± Ø§Ù„Ù‚Ø§Ø¯Ù… ===============
st.markdown('<div class="glass" style="margin-top:1rem;">', unsafe_allow_html=True)
st.markdown("### Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ù„Ù„Ø´Ù‡Ø± Ø§Ù„Ù‚Ø§Ø¯Ù…")
MONTHS_12 = ["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"]

def next_month_label(curr: str) -> str:
    if curr not in MONTHS_12:
        return curr
    i = MONTHS_12.index(curr)
    return MONTHS_12[(i + 1) % 12]

def forecast_figure(df_month_scope: pd.DataFrame):
    if df_month_scope is None or df_month_scope.empty or "Ø§Ù„Ø´Ù‡Ø±" not in df_month_scope.columns:
        return None

    # Ù†Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø´Ù‡Ø± ÙƒÙ…Ø§ ÙÙŠ MONTH_ORDER Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© (Aug, Sep, Oct, Nov)
    month_totals = df_month_scope["Ø§Ù„Ø´Ù‡Ø±"].value_counts().reindex(MONTH_ORDER).dropna()
    if len(month_totals) < 1:
        return None

    # x Ø§Ù„ÙØ¹Ù„ÙŠØ© = Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø´Ù‡Ø± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙØ¹Ù„ÙŠÙ‹Ø§ Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨
    x_labels_actual = month_totals.index.tolist()            # Ù…Ø«Ø§Ù„: ['Aug','Sep','Oct','Nov']
    x_idx = np.arange(len(x_labels_actual)).reshape(-1, 1)   # 0,1,2 â€¦
    y_val = month_totals.values.astype(float)

    # Ø§Ø³Ù… Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ù‚Ø§Ø¯Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ (Ø¨Ø¯ÙˆÙ† modulo)
    next_label = next_month_label(x_labels_actual[-1])

    fig = go.Figure()

    # Ø§Ù„Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„ÙØ¹Ù„ÙŠ
    fig.add_trace(go.Scatter(
        x=x_labels_actual, y=y_val, mode="lines+markers", name="ÙØ¹Ù„ÙŠ",
        line=dict(width=3), marker=dict(size=8)
    ))

    # Ù†Ù…ÙˆØ°Ø¬ Ø®Ø·ÙŠ + Ù†Ù‚Ø·Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ + Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠ
    if _SK_OK and len(y_val) >= 2:
        from sklearn.linear_model import LinearRegression
        model = LinearRegression().fit(x_idx, y_val)
        next_x_numeric = np.array([[len(x_labels_actual)]])  # Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø¹Ø¯ Ø¢Ø®Ø± Ù†Ù‚Ø·Ø© ÙØ¹Ù„ÙŠØ©
        pred = float(model.predict(next_x_numeric)[0])

        resid = y_val - model.predict(x_idx)
        sigma = float(np.std(resid)) if len(resid) > 1 else 0.0
        ci_low = max(0.0, pred - 1.96 * sigma)
        ci_high = pred + 1.96 * sigma

        # Ø®Ø· Ø§Ù„Ø§ØªØ¬Ø§Ù‡: Ù…Ù† Ø£ÙˆÙ„ Ø´Ù‡Ø± ÙØ¹Ù„ÙŠ Ø¥Ù„Ù‰ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹
        line_x_full_num = np.arange(0, len(x_labels_actual) + 1)
        line_x_full_lbl = x_labels_actual + [next_label]
        line_y_full = model.predict(line_x_full_num.reshape(-1, 1))

        fig.add_trace(go.Scatter(
            x=line_x_full_lbl, y=line_y_full, mode="lines", name="Ø§ØªØ¬Ø§Ù‡",
            line=dict(dash="dot", width=2)
        ))
        # Ù†Ù‚Ø·Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ **Nov** (Ø£Ùˆ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„ØªØ§Ù„ÙŠ Ø§Ù„ÙØ¹Ù„ÙŠ)
        fig.add_trace(go.Scatter(
            x=[next_label], y=[pred], mode="markers+text", name="ØªÙˆÙ‚Ø¹ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ù‚Ø§Ø¯Ù…",
            marker=dict(size=12, symbol="diamond"),
            text=[f"{int(round(pred))}"], textposition="top center"
        ))
        # Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠ Ø¹Ù„Ù‰ Ù†ÙØ³ Ø§Ù„ØªØµÙ†ÙŠÙ (Nov)
        fig.add_trace(go.Scatter(
            x=[next_label, next_label], y=[ci_low, ci_high], mode="lines", name="Ù†Ø·Ø§Ù‚ ØªÙ‚Ø±ÙŠØ¨ÙŠ",
            line=dict(color="rgba(164,220,255,.6)", width=8)
        ))
        # Ù†Ø«Ø¨Øª ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ø­ÙˆØ± Ø§Ù„Ø³ÙŠÙ†ÙŠ Ù„Ø¹Ø±Ø¶ Nov Ø¨Ø¹Ø¯ Oct
        fig.update_layout(
            xaxis=dict(categoryorder="array", categoryarray=line_x_full_lbl)
        )
    else:
        # Ø¨Ø¯ÙˆÙ† Sklearn: Ù†Ø¹Ø±Ø¶ Ø§Ù„ÙØ¹Ù„ÙŠ ÙÙ‚Ø· + Ù†Ù‚Ø·Ø© ØªÙ‚Ø¯ÙŠØ± Ù…Ø¨Ø³Ù‘Ø·Ø© Ø¥Ù† ØªÙˆÙØ±Øª Ø´Ù‡Ø±Ø§Ù†
        if len(y_val) >= 2:
            growth = y_val[-1] - y_val[-2]
            pred = int(round(y_val[-1] + growth))
            fig.add_trace(go.Scatter(
                x=[next_label], y=[pred], mode="markers+text", name="ØªÙˆÙ‚Ø¹ Ù…Ø¨Ø³Ù‘Ø·",
                marker=dict(size=12, symbol="diamond"),
                text=[str(pred)], textposition="top center"
            ))
            fig.update_layout(
                xaxis=dict(categoryorder="array", categoryarray=x_labels_actual + [next_label])
            )

    fig.update_layout(
        title="Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø´Ù‡Ø±ÙŠ + Ø§Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„Ù‚Ø§Ø¯Ù…",
        template="plotly_dark", paper_bgcolor="rgba(0,0,0,0)",
        margin=dict(t=60, b=40, l=20, r=20),
        yaxis_title="Ø¹Ø¯Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª", xaxis_title="Ø§Ù„Ø´Ù‡Ø±"
    )
    return fig


fig_pred = forecast_figure(df_for_forecast)
if fig_pred is not None:
    st.plotly_chart(fig_pred, use_container_width=True)
else:
    st.info("Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„Ø¹Ø±Ø¶ Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„ØªÙ†Ø¨Ø¤.")

st.markdown('</div>', unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Map (static lat/lon) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown('<div class="glass" style="margin-top:1rem;">', unsafe_allow_html=True)
st.markdown("### Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©/Ø§Ù„Ù…Ù†Ø·Ù‚Ø©")

CITY_LATLON = {
    "Ø§Ù„Ø±ÙŠØ§Ø¶": (24.7136, 46.6753),
    "Ø¬Ø¯Ø©": (21.4858, 39.1925),
    "Ù…ÙƒØ©": (21.3891, 39.8579),
    "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©": (24.5247, 39.5692),
    "Ø§Ù„Ø¯Ù…Ø§Ù…": (26.3927, 49.9777),
    "Ø§Ù„Ø®Ø¨Ø±": (26.2794, 50.2083),
    "Ø§Ù„Ø·Ø§Ø¦Ù": (21.2703, 40.4158),
    "Ø£Ø¨Ù‡Ø§": (18.2465, 42.5117),
    "Ø­Ø§Ø¦Ù„": (27.5114, 41.7208),
    "ØªØ¨ÙˆÙƒ": (28.3838, 36.5662),
    "Ø¬Ø§Ø²Ø§Ù†": (16.8892, 42.5700),
}
REGION_LATLON = {
    "Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø´Ø±Ù‚ÙŠØ©": (26.5, 49.8),
    "Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø±ÙŠØ§Ø¶": (24.7, 46.7),
    "Ù…Ù†Ø·Ù‚Ø© Ù…ÙƒØ©": (21.4, 40.7),
    "Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©": (24.6, 39.6),
    "Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù‚ØµÙŠÙ…": (26.3, 43.96),
    "Ù…Ù†Ø·Ù‚Ø© ØªØ¨ÙˆÙƒ": (28.4, 36.6),
    "Ù…Ù†Ø·Ù‚Ø© Ø­Ø§Ø¦Ù„": (27.5, 41.7),
    "Ù…Ù†Ø·Ù‚Ø© Ø¬Ø§Ø²Ø§Ù†": (16.9, 42.6),
    "Ù…Ù†Ø·Ù‚Ø© Ù†Ø¬Ø±Ø§Ù†": (17.6, 44.4),
    "Ù…Ù†Ø·Ù‚Ø© Ø¹Ø³ÙŠØ±": (18.2, 42.5),
    "Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø¬ÙˆÙ": (29.97, 40.2),
    "Ø§Ù„Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø´Ù…Ø§Ù„ÙŠØ©": (30.0, 41.0),
    "Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø¨Ø§Ø­Ø©": (20.0, 41.45),
    "Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø·Ø§Ø¦Ù": (21.27, 40.42),
}

def build_map_df(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return pd.DataFrame(columns=["label","lat","lon","count"])

    rows = []

    # Ø§Ø³ØªØ®Ø¯Ù…ÙŠ "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©" (Ø¨Ø¹Ø¯ Ø§Ù„ØªÙˆØ­ÙŠØ¯)ØŒ ÙˆØ¥Ù† Ù…Ø§ ÙˆØ¬Ø¯Øª Ø§Ø±Ø¬Ø¹ÙŠ Ù„Ù„Ø§Ø³Ù… Ø§Ù„Ù‚Ø¯ÙŠÙ… Ø§Ø­ØªÙŠØ§Ø·Ù‹Ø§
    city_col = "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©" if "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©" in df.columns else ("Ø§Ù„Ù…Ø¯ÙŠÙ†Ù‡ " if "Ø§Ù„Ù…Ø¯ÙŠÙ†Ù‡ " in df.columns else None)
    if city_col:
        vc = df[city_col].astype(str).str.strip().value_counts()
        for name, n in vc.items():
            if name in CITY_LATLON:
                lat, lon = CITY_LATLON[name]
                rows.append({"label": name, "lat": lat, "lon": lon, "count": int(n)})

    # Ù„Ùˆ Ù…Ø§ ÙÙŠÙ‡ Ù…Ø¯Ù† Ù…Ø·Ø§Ø¨Ù‚Ø©ØŒ Ø¬Ø±Ø¨ÙŠ Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ "Ø§Ù„Ù…Ù†Ø·Ù‚Ø©"
    if not rows and "Ø§Ù„Ù…Ù†Ø·Ù‚Ø©" in df.columns:
        vc = df["Ø§Ù„Ù…Ù†Ø·Ù‚Ø©"].astype(str).str.strip().value_counts()
        for name, n in vc.items():
            if name in REGION_LATLON:
                lat, lon = REGION_LATLON[name]
                rows.append({"label": name, "lat": lat, "lon": lon, "count": int(n)})

    return pd.DataFrame(rows)

# Ø§Ø¨Ù†Ù Ø§Ù„Ø¯Ø§ØªØ§ Ø«Ù… Ø§Ø±Ø³Ù… Ø«Ù… Ø®Ø²Ù‘Ù†
map_df = build_map_df(filtered)
if not map_df.empty:
    try:
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… scatter_geo Ø§Ù„Ø°ÙŠ ÙŠØ¹Ù…Ù„ Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø­Ø§Ø¬Ø© Ù„Ù€ Mapbox token
        fig_map = px.scatter_geo(
            map_df,
            lat="lat",
            lon="lon",
            size="count",
            color="count",
            hover_name="label",
            hover_data={"lat": False, "lon": False, "count": True},
            size_max=30,
            title="Ø®Ø±ÙŠØ·Ø© ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª",
            projection="natural earth",
        )
        fig_map.update_geos(
            visible=True,
            resolution=50,
            showcountries=True,
            countrycolor="rgba(255,255,255,0.3)",
            showcoastlines=True,
            coastlinecolor="rgba(255,255,255,0.2)",
            showland=True,
            landcolor="rgba(30,30,30,0.5)",
            showocean=True,
            oceancolor="rgba(20,20,20,0.8)",
            bgcolor="rgba(0,0,0,0)",
        )
        fig_map.update_layout(
            paper_bgcolor="rgba(0,0,0,0)",
            plot_bgcolor="rgba(0,0,0,0)",
            margin=dict(t=60, b=40, l=10, r=10),
            template="plotly_dark",
            height=520,
            geo=dict(center=dict(lat=24, lon=45), projection_scale=5),  # ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©
        )
        st.plotly_chart(fig_map, use_container_width=True)
    except Exception as e:
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¯ÙŠÙ„Ø© Ø¨Ø¯ÙˆÙ† Mapbox token
        try:
            if hasattr(px, "scatter_map"):
                fig_map = px.scatter_map(
                    map_df,
                    lat="lat",
                    lon="lon",
                    size="count",
                    color="count",
                    hover_name="label",
                    hover_data={"lat": False, "lon": False, "count": True},
                    size_max=45,
                    zoom=4.2,
                    height=520,
                    title="Ø®Ø±ÙŠØ·Ø© ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª",
                )
                fig_map.update_layout(
                    paper_bgcolor="rgba(0,0,0,0)",
                    margin=dict(t=60, b=40, l=10, r=10),
                    template="plotly_dark",
                )
                st.plotly_chart(fig_map, use_container_width=True)
            else:
                st.warning(f"â— ØªØ¹Ø°Ù‘Ø± Ø±Ø³Ù… Ø§Ù„Ø®Ø±ÙŠØ·Ø©: {e}")
        except Exception as e2:
            st.warning(f"â— ØªØ¹Ø°Ù‘Ø± Ø±Ø³Ù… Ø§Ù„Ø®Ø±ÙŠØ·Ø©: {e2}")
else:
    st.info("Ù„Ø§ ØªØªÙˆÙØ± Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø®Ø±ÙŠØ·Ø©.")

st.markdown('</div>', unsafe_allow_html=True)

# =============== Word Cloud â€” Ø§Ù„Ø®Ø¯Ù…Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ù‡ ===============
st.markdown('<div class="glass" style="margin-top:1rem;">', unsafe_allow_html=True)
st.markdown("### â˜ï¸ Ø³Ø­Ø§Ø¨Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±Ø§ ")

try:
    import matplotlib
    matplotlib.use("Agg")  # Backend ØºÙŠØ± ØªÙØ§Ø¹Ù„ÙŠ Ù„Ø³ØªØ±ÙŠÙ…Ù„ÙŠØª ÙƒÙ„Ø§ÙˆØ¯
    import matplotlib.pyplot as plt
    from wordcloud import WordCloud
    import arabic_reshaper
    from bidi.algorithm import get_display
    from io import BytesIO
    import base64
    from collections import Counter
    import re

    if "Ø§Ù„Ø®Ø¯Ù…Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ù‡" in filtered.columns and not filtered.empty:
        # Ø§Ø¬Ù…Ø¹ Ù†ØµÙˆØµ Ø§Ù„Ø¹Ù…ÙˆØ¯ ÙˆÙ†Ø¸Ù‘ÙÙ‡Ø§
        text_series = filtered["Ø§Ù„Ø®Ø¯Ù…Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ù‡"].dropna().astype(str)
        text_list = [t.strip() for t in text_series.tolist() if t.strip() and t.strip().lower() != "nan"]
        text_raw = " ".join(text_list)

        if len(text_raw) > 3:
            # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (ØªØ´ÙƒÙŠÙ€Ù„ ÙˆØ±Ø¨Ø· Ø§Ù„Ø­Ø±ÙˆÙ + Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø±Ø¶)
            reshaped = arabic_reshaper.reshape(text_raw)
            bidi_text = get_display(reshaped)

            # Ø­Ø¯Ø¯ÙŠ Ø®Ø· Ø¹Ø±Ø¨ÙŠ Ø¥Ù† ÙˆÙØ¬Ø¯ ÙÙŠ assets (ØªÙ… Ø§ÙƒØªØ´Ø§ÙÙ‡ Ù…Ø³Ø¨Ù‚Ù‹Ø§ ÙÙŠ arabic_font_path)
            wc_kwargs = dict(
                width=1200,
                height=550,
                background_color=None,  # Ø´ÙØ§Ù
                mode="RGBA",
                max_words=200,
                prefer_horizontal=0.9,
                collocations=False,
                min_font_size=14
            )
            if arabic_font_path and os.path.isfile(arabic_font_path):
                wc_kwargs["font_path"] = arabic_font_path

            try:
                wc = WordCloud(**wc_kwargs).generate(bidi_text)
            except Exception:
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø¨Ø³Ù‘Ø·Ø© Ø«Ø§Ù†ÙŠØ© Ø¥Ø°Ø§ ÙØ´Ù„Øª Ø§Ù„Ø£ÙˆÙ„Ù‰
                wc = WordCloud(width=1200, height=550, background_color="white", max_words=150).generate(text_raw)

            # Ø§Ø±Ø³Ù… ÙˆØ§Ø­ÙØ¸ Ù„Ù„ØµÙ‚Ù‘ Ø¨Ø§Ù„ØµÙˆØ±Ø©
            plt.ioff()
            fig, ax = plt.subplots(figsize=(14, 6), dpi=150, facecolor="none")
            ax.imshow(wc, interpolation="bilinear")
            ax.axis("off")
            fig.patch.set_alpha(0.0)
            plt.tight_layout(pad=0)

            buf = BytesIO()
            fig.savefig(buf, format="png", bbox_inches="tight", pad_inches=0, transparent=True)
            buf.seek(0)
            img_b64 = base64.b64encode(buf.read()).decode("utf-8")
            plt.close(fig); buf.close()

            st.markdown(
                f'<div style="text-align:center;"><img src="data:image/png;base64,{img_b64}" '
                f'style="max-width:100%;height:auto;border-radius:10px;" /></div>',
                unsafe_allow_html=True
            )
        else:
            st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© ÙÙŠ Ø¹Ù…ÙˆØ¯ **Ø§Ù„Ø®Ø¯Ù…Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ù‡** Ø¶Ù…Ù† Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ù…Ø­Ø¯Ø¯.")
    else:
        st.info("Ù„Ø§ ÙŠØªÙˆÙØ± Ø¹Ù…ÙˆØ¯ **Ø§Ù„Ø®Ø¯Ù…Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ù‡** ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØµÙØ§Ø©.")

except ImportError:
    # Ø¨Ø¯ÙŠÙ„ Ù†ØµÙ‘ÙŠ Ø¨Ø³ÙŠØ· Ø¹Ù†Ø¯ ØºÙŠØ§Ø¨ Ø§Ù„Ø­Ø²Ù…
    if "Ø§Ù„Ø®Ø¯Ù…Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ù‡" in filtered.columns and not filtered.empty:
        all_text = " ".join(filtered["Ø§Ù„Ø®Ø¯Ù…Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ù‡"].dropna().astype(str).tolist())
        words = re.findall(r"\b\w+\b", all_text, re.UNICODE)
        common = Counter(words).most_common(20)
        if common:
            st.markdown("**Ø£ÙƒØ«Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø´ÙŠÙˆØ¹Ù‹Ø§ (Ø¨Ø¯ÙŠÙ„ Ø¹Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø©):**")
            st.markdown(" | ".join([f"**{w}** ({c})" for w, c in common]))
        else:
            st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ ÙƒÙ„Ù…Ø§Øª Ù„Ø¹Ø±Ø¶Ù‡Ø§.")
    else:
        st.info("Ù„Ø§ ÙŠØªÙˆÙØ± Ø¹Ù…ÙˆØ¯ **Ø§Ù„Ø®Ø¯Ù…Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ù‡** ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØµÙØ§Ø©.")

except Exception as e:
    st.warning(f"ØªØ¹Ø°Ù‘Ø± Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø­Ø§Ø¨Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª: {e}")
    # Ø¨Ø¯ÙŠÙ„ Ø§Ø­ØªÙŠØ§Ø·ÙŠ
    try:
        from collections import Counter
        import re
        if "Ø§Ù„Ø®Ø¯Ù…Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ù‡" in filtered.columns and not filtered.empty:
            all_text = " ".join(filtered["Ø§Ù„Ø®Ø¯Ù…Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ù‡"].dropna().astype(str).tolist())
            words = re.findall(r"\b\w+\b", all_text, re.UNICODE)
            common = Counter(words).most_common(20)
            if common:
                st.markdown("**Ø£ÙƒØ«Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø´ÙŠÙˆØ¹Ù‹Ø§ (Ø¨Ø¯ÙŠÙ„ Ø¹Ù† Ø§Ù„Ø³Ø­Ø§Ø¨Ø©):**")
                st.markdown(" | ".join([f"**{w}** ({c})" for w, c in common]))
    except Exception:
        pass

st.markdown('</div>', unsafe_allow_html=True)
# =============== Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªÙØ§ØµÙŠÙ„ + Ø§Ù„Ø¨Ø­Ø« ===============
st.markdown('<div class="glass" style="margin-top:1rem;">', unsafe_allow_html=True)
st.markdown("### Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ")
# ØªØ­Ø¯ÙŠØ¯ Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¹Ø±Ø¶ Ø¨ØªØ±ØªÙŠØ¨ ÙˆØ§Ø¶Ø­: Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„ ÙˆØ±Ù‚Ù… Ø§Ù„Ø¬ÙˆØ§Ù„ ÙÙŠ Ø§Ù„Ø£ÙˆÙ„
cols_priority = ['Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„', 'Ø±Ù‚Ù… Ø§Ù„Ø¬ÙˆØ§Ù„']  # Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª
cols_secondary = ['Ø§Ù„Ø´Ù‡Ø±','Ø§Ù„ØªØ§Ø±ÙŠØ®','Ø§Ù„ØªØ§Ø±ÙŠØ®/Date','ÙˆØ³Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹','Ø±Ù‚Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹',
                  'Ø§Ù„Ù…Ù†Ø·Ù‚Ø©','Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©','Ø§Ù„Ø´Ø±ÙƒØ©','Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø©','Ø§Ù„Ø®Ø¯Ù…Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ù‡','Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (Ù…Ù„Ù)']
cols_base = cols_priority + cols_secondary

# Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙ‚Ø·ØŒ Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªØ±ØªÙŠØ¨
show_cols = [c for c in cols_base if c in filtered.columns]

q = st.text_input("Ø§Ø¨Ø­Ø« Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¬Ø¯ÙˆÙ„ (Ø§Ù„Ø§Ø³Ù…/Ø§Ù„Ø´Ø±ÙƒØ©/Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©/Ø§Ù„Ù†ÙˆØ¹/Ø§Ù„Ø®Ø¯Ù…Ø©...)", "")
table_df = filtered.copy()
if q.strip() and show_cols:
    ql = q.strip().lower()
    mask = np.zeros(len(table_df), dtype=bool)
    for c in show_cols:
        s = table_df[c].astype(str).str.lower()
        mask |= s.str.contains(ql, na=False)
    table_df = table_df[mask]
if show_cols:
    # ØªØ±Ø¬Ù…Ø© Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ù„Ù„Ø¹Ø±Ø¶
    if "Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (Ù…Ù„Ù)" in table_df.columns:
        table_df["Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (Ù…Ù„Ù)"] = table_df["Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (Ù…Ù„Ù)"].map(provider_to_ar)
    
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø­ÙÙˆØ¸Ø© Ø¨Ø¯ÙˆÙ† ØªØ¹Ø¯ÙŠÙ„ Ø£Ùˆ Ø­Ø°Ù
    # Ø¹Ø±Ø¶ Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„ ÙƒÙ…Ø§ Ù‡Ùˆ Ù…Ø³Ø¬Ù„ (Ø³ÙˆØ§Ø¡ ÙƒØ§Ù† Ø§Ø³Ù… Ø­Ù‚ÙŠÙ‚ÙŠ Ø£Ùˆ "Ø¹Ù…ÙŠÙ„")
    display_df = table_df[show_cols].reset_index(drop=True).copy()
    
    # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ÙˆØ¶ÙˆØ­
    st.dataframe(display_df, use_container_width=True, height=460)
st.markdown('</div>', unsafe_allow_html=True)

# =============== Ù…Ù„Ø®Øµ Ø°ÙƒÙŠ Ù…Ø®ØªØµØ± ===============
st.markdown('<div class="glass" style="margin-top:1rem;">', unsafe_allow_html=True)
st.markdown("### ğŸ¤– Ù…Ù„Ø®Ù‘Øµ Ø°ÙƒÙŠ")
def quick_summary(df: pd.DataFrame) -> str:
    if df.empty: return "Ù„Ø§ ØªØªÙˆÙØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø¶Ù…Ù† Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ù…Ø­Ø¯Ø¯."
    parts = [f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª: **{len(df)}**."]
    if "Ø§Ù„Ù…Ù†Ø·Ù‚Ø©" in df.columns and not df["Ø§Ù„Ù…Ù†Ø·Ù‚Ø©"].value_counts().empty:
        parts.append(f"Ø§Ù„Ø£ÙƒØ«Ø± Ù†Ø´Ø§Ø·Ù‹Ø§: **{df['Ø§Ù„Ù…Ù†Ø·Ù‚Ø©'].value_counts().idxmax()}**.")
    if "Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø©" in df.columns and not df["Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø©"].value_counts().empty:
        parts.append(f"Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§: **{df['Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø©'].value_counts().idxmax()}**.")
    if "Ø§Ù„Ø´Ø±ÙƒØ©" in df.columns and not df["Ø§Ù„Ø´Ø±ÙƒØ©"].value_counts().empty:
        parts.append(f"Ø§Ù„Ø´Ø±ÙƒØ© Ø§Ù„Ø£Ø¨Ø±Ø²: **{df['Ø§Ù„Ø´Ø±ÙƒØ©'].value_counts().idxmax()}**.")
    return " ".join(parts)
st.write(quick_summary(filtered))
st.markdown('</div>', unsafe_allow_html=True)

