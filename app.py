# -*- coding: utf-8 -*-
import os, glob, io, base64, re
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st

# ========== (Ø¥Ø¶Ø§ÙØ© Ø¬Ø¯ÙŠØ¯Ø©) Ø³Ùƒikit-learn Ø§Ø®ØªÙŠØ§Ø±ÙŠ Ù„Ù„ØªÙ†Ø¨Ø¤ ==========
_SK_OK = True
try:
    from sklearn.linear_model import LinearRegression
except Exception:
    _SK_OK = False
# ============================================================

# WordCloud + Arabic support
import matplotlib.pyplot as plt
from wordcloud import WordCloud
try:
    import arabic_reshaper
    from bidi.algorithm import get_display
    AR_SUPPORT = True
except Exception:
    AR_SUPPORT = False

# =============== Ø¥Ø¹Ø¯Ø§Ø¯ Ø¹Ø§Ù… + Ø´Ø¹Ø§Ø± ===============
APP_DIR = os.path.dirname(os.path.abspath(__file__))
ASSETS_DIR = os.path.join(APP_DIR, "assets")
LOGO_DIR = ASSETS_DIR
LOGO_FILE_CANDIDATES = ["Aljeri-logo.png.png","logo.jpg","logo.jpeg","logo.svg"]

def read_logo_bytes():
    if os.path.isdir(LOGO_DIR):
        for name in LOGO_FILE_CANDIDATES:
            p = os.path.join(LOGO_DIR, name)
            if os.path.isfile(p):
                with open(p, "rb") as f:
                    return f.read()
    if os.path.isfile(LOGO_DIR):
        with open(LOGO_DIR, "rb") as f:
            return f.read()
    return None

logo_bytes = read_logo_bytes()

st.set_page_config(page_title="ØªÙ‚Ø±ÙŠØ± Ù‚Ø³Ù… Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ 2025", page_icon="ğŸ“", layout="wide")

DARK_GLASS_CSS = """
<style>
html, body, [data-testid="stAppViewContainer"], .block-container { direction: rtl; }
[data-testid="stAppViewContainer"] {
  background: radial-gradient(1200px 800px at 0% 0%, rgba(40,45,60,0.55) 0%, rgba(15,18,25,0.95) 60%),
              radial-gradient(1000px 700px at 100% 0%, rgba(30,35,50,0.55) 0%, rgba(15,18,25,0.95) 60%);
  backdrop-filter: blur(18px);
}
.block-container { padding-top: 1.2rem; max-width: 1400px; }
.glass {
  background: linear-gradient(180deg, rgba(255,255,255,0.09), rgba(255,255,255,0.03));
  border: 1px solid rgba(255,255,255,0.12);
  box-shadow: 0 10px 30px rgba(0,0,0,0.35);
  backdrop-filter: blur(18px);
  border-radius: 18px; padding: 1.1rem 1.2rem;
}
h1, h2, h3, h4, h5 { color: #ECF2FF !important; letter-spacing: .3px; }
body, p, div, label, span { color: #E3E9F5 !important; }
.header-flex { display:flex; align-items:center; justify-content:space-between; padding:.8rem 1rem; margin-bottom:.6rem; }
.header-left { display:flex; gap:.75rem; align-items:center; flex-direction:row-reverse; }
.logo-box {
  width: 84px; height: 84px; border-radius: 18px; overflow:hidden;
  background:linear-gradient(145deg,#0b1222,#0f172a);
  display:flex; align-items:center; justify-content:center;
  box-shadow:0 12px 24px rgba(0,0,0,0.5), inset 0 1px 0 rgba(255,255,255,0.06);
}
.logo-box img { width:100%; height:100%; object-fit:contain; }
.kpi {
  position: relative; border-radius: 18px; padding: 1rem; text-align: center; min-height: 150px;
  display:flex; flex-direction:column; justify-content:center;
  background: linear-gradient(180deg, rgba(255,255,255,0.08), rgba(255,255,255,0.03));
  border: 1px solid rgba(255,255,255,0.14);
  box-shadow: 0 18px 40px rgba(0,0,0,0.35), inset 0 1px 0 rgba(255,255,255,0.05);
}
.kpi .title { color:#9FB3C8; font-size:.95rem; margin-bottom:.35rem; }
.kpi .value { font-size:2rem; font-weight:800; color:#F5FAFF; line-height:1.15; }
.badge {
  display:inline-block; padding:.25rem .55rem; border-radius:999px; font-size:.85rem;
  background: rgba(255,255,255,0.08); border: 1px solid rgba(255,255,255,0.16); color: #cfe4ff;
}
hr { border:none; height:1px; background:rgba(255,255,255,0.12); margin:12px 0; }
</style>
"""
st.markdown(DARK_GLASS_CSS, unsafe_allow_html=True)

if logo_bytes:
    b64 = base64.b64encode(logo_bytes).decode("utf-8")
    logo_img_html = f'<div class="logo-box"><img src="data:image/png;base64,{b64}" alt="logo"/></div>'
else:
    logo_img_html = '<div class="logo-box"><span style="font-size:26px;">ğŸ“</span></div>'

st.markdown(
    f"""
    <div class="glass header-flex">
      <div class="header-left">
        <div>
          <h2 style="margin:0;">ØªÙ‚Ø±ÙŠØ± Ù‚Ø³Ù… Ø®Ø¯Ù…Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ 2025</h2>
          <div style="color:#9FB3C8;margin-top:-4px;font-size:.95rem;">Ø¹Ø±Ø¶ ØªÙØ§Ø¹Ù„ÙŠ Ù„Ù„Ù…Ø¤Ø´Ø±Ø§Øª ÙˆØ§Ù„Ø±Ø³ÙˆÙ… ÙˆØ§Ù„Ø®Ø±ÙŠØ·Ø©</div>
        </div>
      </div>
      {logo_img_html}
    </div>
    """,
    unsafe_allow_html=True
)

# =============== Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø´Ù‡ÙˆØ± ÙˆØªØ±Ø¬ÙÙ…Ø§Øª Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ ===============
MONTH_ORDER = ["Aug", "Sep", "Oct"]  # Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ø© Ø§Ù„Ø¢Ù†
MONTH_INDEX = {m:i for i,m in enumerate(MONTH_ORDER)}
MONTH_MAP = {"Jan":1,"Feb":2,"Mar":3,"Apr":4,"May":5,"Jun":6,"Jul":7,"Aug":8,"Sep":9,"Oct":10,"Nov":11,"Dec":12}
INV_MONTH_MAP = {v:k for k,v in MONTH_MAP.items()}

PROVIDER_AR = {
    "Aljauhara": "Ø§Ù„Ø¬ÙˆÙ‡Ø±Ø©",
    "Reem": "Ø±ÙŠÙ…",
    "Ahad": "Ø¹Ù‡Ø¯",
    "Shouq": "Ø´ÙˆÙ‚",
    "Abdulmageed": "Ø¹Ø¨Ø¯Ø§Ù„Ù…Ø¬ÙŠØ¯",
    "Abdulkareem": "Ø¹Ø¨Ø¯Ø§Ù„ÙƒØ±ÙŠÙ…",
}
def provider_to_ar(name: str) -> str:
    return PROVIDER_AR.get(name, name)

def ar_to_provider(ar_name: str) -> str:
    rev = {v:k for k,v in PROVIDER_AR.items()}
    return rev.get(ar_name, ar_name)

# --- ØªÙˆØ­ÙŠØ¯ Ù‚ÙŠÙ… Ø§Ù„Ø´Ù‡Ø± (Oct/October/Ø£ÙƒØªÙˆØ¨Ø±â€¦ -> Oct) ---
MONTH_SYNONYMS = {
    "aug": "Aug", "aug.": "Aug", "august": "Aug", "Ø£ØºØ³Ø·Ø³": "Aug", "Ø§ØºØ³Ø·Ø³": "Aug",
    "sep": "Sep", "sep.": "Sep", "september": "Sep", "Ø³Ø¨ØªÙ…Ø¨Ø±": "Sep",
    "oct": "Oct", "oct.": "Oct", "october": "Oct", "Ø£ÙƒØªÙˆØ¨Ø±": "Oct", "Ø§ÙƒØªÙˆØ¨Ø±": "Oct",
}
def normalize_month_value(val, dt):
    s = (str(val).strip() if val is not None else "").lower()
    if s in MONTH_SYNONYMS:
        canon = MONTH_SYNONYMS[s]
        return canon if canon in MONTH_ORDER else np.nan
    if pd.notna(dt):
        mnum = int(dt.month); canon = INV_MONTH_MAP.get(mnum)
        return canon if canon in MONTH_ORDER else np.nan
    if len(s) >= 3 and s[:3].title() in MONTH_MAP:
        canon = s[:3].title()
        return canon if canon in MONTH_ORDER else np.nan
    return np.nan

# =============== ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ===============
def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        return df
    df = df.rename(columns=lambda c: str(c).strip())
    mapping = {
        "Ø§Ù„ØªØ§Ø±ÙŠØ® ": "Ø§Ù„ØªØ§Ø±ÙŠØ®",
        "Date": "Ø§Ù„ØªØ§Ø±ÙŠØ®", "date": "Ø§Ù„ØªØ§Ø±ÙŠØ®",
        "Ø§Ù„Ù…Ù†Ø·Ù‚Ù‡": "Ø§Ù„Ù…Ù†Ø·Ù‚Ø©",
        "Ø§Ù„Ù…Ø¯ÙŠÙ†Ù‡ ": "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©", "Ø§Ù„Ù…Ø¯ÙŠÙ†Ù‡": "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©",
        "Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©": "Ø§Ù„Ø®Ø¯Ù…Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ù‡",
        "Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ù‡": "Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø©",
        "Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„ ": "Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„",
        "Ø±Ù‚Ù… Ø§Ù„Ø¬ÙˆØ§Ù„ ": "Ø±Ù‚Ù… Ø§Ù„Ø¬ÙˆØ§Ù„",
    }
    df = df.rename(columns={c: mapping.get(c, c) for c in df.columns})
    return df

# =============== Ø¨Ù†Ø§Ø¡ Ø§Ù„ØªØ§Ø±ÙŠØ® Ù…Ù† (Ø§Ù„Ø´Ù‡Ø± + Ø§Ù„ÙŠÙˆÙ…) ===============
def build_date_from_month_day(row: pd.Series):
    m = str(row.get("Ø§Ù„Ø´Ù‡Ø±","")).strip()
    raw = str(row.get("Ø§Ù„ØªØ§Ø±ÙŠØ®","")).strip()
    if raw and ("/" in raw or "-" in raw):
        dt = pd.to_datetime(raw, dayfirst=True, errors="coerce")
        if pd.notna(dt): return dt
    if m in MONTH_MAP:
        try:
            day = int(float(raw)) if raw else 1
            return pd.Timestamp(year=2025, month=MONTH_MAP[m], day=day)
        except Exception:
            return pd.NaT
    return pd.NaT

# =============== Ø£Ø³Ø§Ø¨ÙŠØ¹ Ø§Ù„Ø£Ø­Ø¯â†’Ø§Ù„Ø®Ù…ÙŠØ³ ÙˆØªØ±Ù‚ÙŠÙ…Ù‡Ø§ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø´Ù‡Ø± ===============
def add_week_columns(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty or "Ø§Ù„ØªØ§Ø±ÙŠØ®/Date" not in df.columns:
        df["ISO_Year"]=np.nan; df["ISO_Week"]=np.nan
        df["WeekStart"]=pd.NaT; df["WeekEnd"]=pd.NaT
        df["Ø±Ù‚Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"]=np.nan; df["ÙˆØ³Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"]=""
        return df

    d = df.copy()
    wd = d["Ø§Ù„ØªØ§Ø±ÙŠØ®/Date"].dt.weekday              # Monday=0..Sunday=6
    start_offset = (wd + 1) % 7                     # Ù„Ù„Ø£Ø­Ø¯
    d["WeekStart"] = d["Ø§Ù„ØªØ§Ø±ÙŠØ®/Date"] - pd.to_timedelta(start_offset, unit="D")
    d["WeekEnd"]   = d["WeekStart"] + pd.to_timedelta(4, unit="D")  # Ø§Ù„Ø®Ù…ÙŠØ³

    d["ISO_Year"]  = d["WeekStart"].dt.isocalendar().year
    d["ISO_Week"]  = d["WeekStart"].dt.isocalendar().week

    if "Ø§Ù„Ø´Ù‡Ø±" in d.columns:
        def rank_weeks_in_month(g):
            mnum = MONTH_MAP.get(g.name, None)
            if not mnum:
                gg=g.copy(); gg["Ø±Ù‚Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"]=np.nan; gg["ÙˆØ³Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"]=""
                return gg

            year = 2025
            month_start = pd.Timestamp(year=year, month=mnum, day=1)
            next_month = mnum + 1 if mnum < 12 else 1
            next_year  = year + 1 if mnum == 12 else year
            month_end  = pd.Timestamp(year=next_year, month=next_month, day=1) - pd.Timedelta(days=1)

            weeks = (
                g.dropna(subset=["WeekStart","WeekEnd"])
                 .loc[
                  ((g["WeekStart"]>=month_start)&(g["WeekStart"]<=month_end)) |
                  ((g["WeekEnd"]  >=month_start)&(g["WeekEnd"]  <=month_end))
                 , ["WeekStart","WeekEnd"]]
                 .drop_duplicates()
                 .sort_values("WeekStart")
                 .reset_index(drop=True)
            )
            weeks["rank"] = range(1, len(weeks)+1)
            rank_map = {ws:int(r) for ws,r in zip(weeks["WeekStart"], weeks["rank"])}

            def label(ws,we):
                if pd.isna(ws) or pd.isna(we): return ""
                r = rank_map.get(ws, np.nan)
                return f"Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ {r} ({ws.strftime('%b %d')}â€“{we.strftime('%b %d')})"

            gg = g.copy()
            gg["Ø±Ù‚Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"] = gg["WeekStart"].map(rank_map).astype("float")
            gg["ÙˆØ³Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"] = [label(ws,we) for ws,we in zip(gg["WeekStart"], gg["WeekEnd"])]
            return gg

        d = d.groupby("Ø§Ù„Ø´Ù‡Ø±", group_keys=False).apply(rank_weeks_in_month)
    else:
        d["Ø±Ù‚Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"]=np.nan; d["ÙˆØ³Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"]=""

    return d

# =============== ØªØ­Ù…ÙŠÙ„ ÙƒÙ„ CSV Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ===============
@st.cache_data(show_spinner=True)
def load_all(folder="data"):
    files = sorted(glob.glob(os.path.join(folder, "*.csv")))
    datasets = {}
    for path in files:
        provider = os.path.splitext(os.path.basename(path))[0].strip()

        df = None
        err_msg = None
        for attempt in range(2):
            try:
                df = pd.read_csv(
                    path,
                    encoding="utf-8-sig",
                    engine="python",
                    on_bad_lines="skip",
                    sep=",",
                    quotechar='"',
                    skipinitialspace=True
                )
                break
            except Exception as e:
                err_msg = str(e)

        if df is None:
            st.error(f"ØªØ¹Ø°Ù‘Ø± Ù‚Ø±Ø§Ø¡Ø© {os.path.basename(path)} â€” {err_msg}")
            continue

        if df.empty:
            st.warning(f"Ø§Ù„Ù…Ù„Ù {os.path.basename(path)} ÙØ§Ø±Øº Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ.")
            continue

        # Ù†Ø¸Ø§ÙØ© Ø£Ø³Ø§Ø³ÙŠØ©
        df.dropna(how="all", inplace=True)
        df = normalize_columns(df)

        # ØªØ§Ø±ÙŠØ® Ù…ÙˆØ­Ù‘Ø¯
        df["Ø§Ù„ØªØ§Ø±ÙŠØ®/Date"] = pd.to_datetime(df.apply(build_date_from_month_day, axis=1), errors="coerce")

        # --- Ø§Ù„Ø´Ù‡Ø±: ØªÙˆØ­ÙŠØ¯ Ù‚ÙˆÙŠ Ù‚Ø¨Ù„ Ø§Ù„Ø­ØµØ± ---
        orig_month_col = df["Ø§Ù„Ø´Ù‡Ø±"] if "Ø§Ù„Ø´Ù‡Ø±" in df.columns else pd.Series([None]*len(df))
        df["Ø§Ù„Ø´Ù‡Ø±"] = [normalize_month_value(m, dt) for m, dt in zip(orig_month_col, df["Ø§Ù„ØªØ§Ø±ÙŠØ®/Date"])]
        df["Ø§Ù„Ø´Ù‡Ø±"] = df["Ø§Ù„Ø´Ù‡Ø±"].where(df["Ø§Ù„Ø´Ù‡Ø±"].isin(MONTH_ORDER), np.nan)

        # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù†ØµÙˆØµ
        for col in ["Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„","Ø±Ù‚Ù… Ø§Ù„Ø¬ÙˆØ§Ù„","Ø§Ù„Ù…Ù†Ø·Ù‚Ø©","Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©","Ø§Ù„Ø´Ø±ÙƒØ©","Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø©","Ø§Ù„Ø®Ø¯Ù…Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ù‡","Ø§Ù„Ø´Ù‡Ø±"]:
            if col in df.columns:
                df[col] = df[col].astype(str).str.strip()

        # Ø¨Ù†Ø§Ø¡ Ø£Ø³Ø§Ø¨ÙŠØ¹ Ø§Ù„Ø¹Ù…Ù„
        df = add_week_columns(df)

        # Ù…ØµØ¯Ø± Ø§Ù„Ù…Ù„Ù
        df["Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (Ù…Ù„Ù)"] = provider
        datasets[provider] = df

        if err_msg is not None:
            st.warning(f"ØªÙ… ØªØ®Ø·Ù‘ÙŠ Ø£Ø³Ø·Ø± ØªØ§Ù„ÙØ© ÙÙŠ {os.path.basename(path)} Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø¹Ù…Ù„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚.")

    if datasets:
        all_df = pd.concat(list(datasets.values()), ignore_index=True, sort=False)
        datasets["__ALL__"] = all_df

    return datasets

datasets = load_all()
if not datasets:
    st.error("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø£ÙŠ CSV Ø¯Ø§Ø®Ù„ data/. Ø£Ø¶ÙŠÙÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª Ø«Ù… Ø£Ø¹ÙŠØ¯ÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„.")
    st.stop()

# =============== Ø§Ù„Ù…Ø±Ø´Ù‘Ø­Ø§Øª ===============
providers = [k for k in datasets.keys() if k != "__ALL__"]
providers_ar = ["Ø§Ù„ÙƒÙ„"] + [provider_to_ar(p) for p in providers]

with st.form("main_filters"):
    c1, c2, c3 = st.columns([1.2, 1.2, 1.2])

    with c1:
        st.markdown('<div class="glass"><b>Ù…Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø®Ø¯Ù…Ø©</b>', unsafe_allow_html=True)
        provider_choice_ar = st.selectbox("Ø§Ø®ØªØ±", providers_ar, index=0)
        st.markdown('</div>', unsafe_allow_html=True)

    # Ù†Ø·Ø§Ù‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø©
    if provider_choice_ar == "Ø§Ù„ÙƒÙ„":
        provider_key = "__ALL__"
        df_scope = datasets["__ALL__"].copy()
    else:
        provider_key = ar_to_provider(provider_choice_ar)
        df_scope = datasets.get(provider_key, pd.DataFrame()).copy()

    with c2:
        st.markdown('<div class="glass"><b>ØªØµÙÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø´Ù‡Ø±</b>', unsafe_allow_html=True)
        months_av = []
        if "Ø§Ù„Ø´Ù‡Ø±" in df_scope.columns:
            months_av = [m for m in MONTH_ORDER if m in df_scope["Ø§Ù„Ø´Ù‡Ø±"].dropna().unique().tolist()]
        month_choice = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø´Ù‡Ø±", ["Ø§Ù„ÙƒÙ„"] + months_av, index=0)
        st.markdown('</div>', unsafe_allow_html=True)

    with c3:
        st.markdown('<div class="glass"><b>ØªØµÙÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø´Ù‡Ø±</b>', unsafe_allow_html=True)
        # Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ ÙŠØ¸Ù‡Ø± Ø¯Ø§Ø¦Ù…Ù‹Ø§: Ù†Ø¬Ù…Ø¹ Ø£Ø³Ø§Ø¨ÙŠØ¹ Ù†Ø·Ø§Ù‚ df_scope Ø«Ù… Ù†Ù‚ÙŠÙ‘Ø¯ Ø¥Ø°Ø§ ØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø´Ù‡Ø±
        week_options = ["Ø§Ù„ÙƒÙ„"]
        tmp = df_scope.copy()
        if month_choice != "Ø§Ù„ÙƒÙ„":
            tmp = tmp[tmp["Ø§Ù„Ø´Ù‡Ø±"] == month_choice]
        if "ÙˆØ³Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹" in tmp.columns and not tmp.empty:
            uniq = (
                tmp.dropna(subset=["WeekStart","WeekEnd"])
                   .drop_duplicates(subset=["WeekStart"])
                   .sort_values(["WeekStart"])
            )
            week_options += uniq["ÙˆØ³Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"].tolist()
        week_choice = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹", week_options, index=0)
        st.markdown('</div>', unsafe_allow_html=True)

    st.form_submit_button("ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø±Ø´Ù‘Ø­Ø§Øª âœ…")

# =============== ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØµÙÙŠØ© ===============
filtered = df_scope.copy()
if month_choice != "Ø§Ù„ÙƒÙ„":
    filtered = filtered[filtered["Ø§Ù„Ø´Ù‡Ø±"] == month_choice]
if week_choice != "Ø§Ù„ÙƒÙ„" and "ÙˆØ³Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹" in filtered.columns:
    filtered = filtered[filtered["ÙˆØ³Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"] == week_choice]

# =============== KPI + Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© ===============
total_calls = int(len(filtered))

def top_month_in_scope(df):
    if df.empty or "Ø§Ù„Ø´Ù‡Ø±" not in df.columns: return None, 0
    s = df["Ø§Ù„Ø´Ù‡Ø±"].value_counts().sort_values(ascending=False)
    return (s.index[0], int(s.iloc[0])) if len(s) else (None, 0)

def average_for_selection(df: pd.DataFrame, month_choice: str, week_choice: str):
    """
    - Ø¥Ø°Ø§ ØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø£Ø³Ø¨ÙˆØ¹: Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„ÙŠÙˆÙ…ÙŠ (Ø£Ø­Ø¯â€“Ø®Ù…ÙŠØ³).
    - Ø¥Ø°Ø§ ØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø´Ù‡Ø± ÙÙ‚Ø·: Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ Ø¯Ø§Ø®Ù„ Ù‡Ø°Ø§ Ø§Ù„Ø´Ù‡Ø±.
    - Ø¥Ø°Ø§ Ù„Ù… ÙŠÙØ­Ø¯Ù‘ÙØ¯ Ø´Ù‡Ø±/Ø£Ø³Ø¨ÙˆØ¹: Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø´Ù‡Ø±ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ø­Ø§Ù„ÙŠ.
    """
    if df.empty: return 0.0, "â€”"

    if week_choice != "Ø§Ù„ÙƒÙ„":
        if "WeekStart" not in df.columns or "WeekEnd" not in df.columns:
            return 0.0, "â€”"
        wdf = df[df["ÙˆØ³Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹"] == week_choice].copy()
        if wdf.empty:
            return 0.0, "â€”"
        ws = pd.to_datetime(wdf["WeekStart"].iloc[0])
        we = pd.to_datetime(wdf["WeekEnd"].iloc[0])
        day_count = max(1, min(int((we - ws).days) + 1, 5))  # Ø£Ø­Ø¯..Ø®Ù…ÙŠØ³
        avg_per_day = len(wdf) / day_count
        return float(avg_per_day), f"Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„ÙŠÙˆÙ…ÙŠ â€” {ws.strftime('%b %d')}â€“{we.strftime('%b %d')}"

    if month_choice != "Ø§Ù„ÙƒÙ„":
        if "WeekStart" not in df.columns:
            return 0.0, "â€”"
        mdf = df[df["Ø§Ù„Ø´Ù‡Ø±"] == month_choice]
        if mdf.empty:
            return 0.0, "â€”"
        week_sizes = mdf.groupby("WeekStart").size()
        if len(week_sizes) == 0:
            return 0.0, "â€”"
        return float(week_sizes.mean()), f"Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ â€” Ø´Ù‡Ø± {month_choice}"

    if "Ø§Ù„Ø´Ù‡Ø±" in df.columns:
        month_sizes = df.groupby("Ø§Ù„Ø´Ù‡Ø±").size()
        if len(month_sizes)==0: return 0.0, "â€”"
        return float(month_sizes.mean()), "Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ø´Ù‡Ø±ÙŠ â€” Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ø­Ø§Ù„ÙŠ"

    return 0.0, "â€”"

k1,k2,k3 = st.columns(3)
with k1:
    scope_title = "Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª" if provider_key=="__ALL__" else f"Ø§Ù„Ù…Ù„Ù: {provider_to_ar(provider_key)}"
    st.markdown(f"""<div class="kpi">
        <div class="title">Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª â€” {scope_title}</div>
        <div class="value">{total_calls}</div>
    </div>""", unsafe_allow_html=True)

m_name, m_val = top_month_in_scope(filtered if provider_key=="__ALL__" else datasets[provider_key])
with k2:
    st.markdown(f"""<div class="kpi">
        <div class="title">Ø£Ø¹Ù„Ù‰ Ø´Ù‡Ø± Ø¶Ù…Ù† Ø§Ù„Ù†Ø·Ø§Ù‚</div>
        <div class="value">{m_name or 'â€”'}</div>
        <div class="badge">Ø¹Ø¯Ø¯: {m_val}</div>
    </div>""", unsafe_allow_html=True)

avg_val, avg_label = average_for_selection(filtered, month_choice, week_choice)
with k3:
    st.markdown(f"""<div class="kpi">
        <div class="title">Ø§Ù„Ù…ØªÙˆØ³Ø· (Ø­Ø³Ø¨ Ø§Ù„ØªØµÙÙŠØ©)</div>
        <div class="value">{round(avg_val,2)}</div>
        <div class="badge">{avg_label}</div>
    </div>""", unsafe_allow_html=True)

# =============== (Ø¥Ø¶Ø§ÙØ© Ø¬Ø¯ÙŠØ¯Ø©) KPI Ù„ØªÙˆÙ‚Ù‘Ø¹ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ù‚Ø§Ø¯Ù… ===============
def calc_forecast(df_month_scope: pd.DataFrame):
    """
    ÙŠØ¨Ù†ÙŠ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø´Ù‡Ø±ÙŠ Ù…Ù† df_month_scope (Ù‚Ø¨Ù„ ØªØ±Ø´ÙŠØ­ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹)ØŒ
    Ø«Ù… ÙŠØ·Ø¨Ù‘Ù‚ LinearRegression Ø¥Ù† ØªÙˆÙØ±ØªØŒ Ø£Ùˆ ØªÙ‚Ø¯ÙŠØ± Ø¨Ø³ÙŠØ· Ø¥Ù† Ù„Ù… ØªØªÙˆÙØ±.
    """
    if df_month_scope is None or df_month_scope.empty or "Ø§Ù„Ø´Ù‡Ø±" not in df_month_scope.columns:
        return None, None, None

    month_totals = df_month_scope["Ø§Ù„Ø´Ù‡Ø±"].value_counts().reindex(MONTH_ORDER).dropna()
    if len(month_totals) < 1:
        return None, None, None

    x = np.array([MONTH_INDEX[m] for m in month_totals.index]).reshape(-1,1)
    y = month_totals.values.astype(float)

    # Ù†Ù…ÙˆØ°Ø¬ Ø®Ø·ÙŠ Ù…Ø¹ Ù†Ø·Ø§Ù‚ ØªÙ‚Ø±ÙŠØ¨ÙŠ
    if _SK_OK and len(y) >= 2:
        model = LinearRegression().fit(x, y)
        next_x_val = x[-1][0] + 1
        pred = float(model.predict(np.array([[next_x_val]]) )[0])
        resid = y - model.predict(x)
        sigma = float(np.std(resid)) if len(resid) > 1 else 0.0
        ci_low = max(0.0, pred - 1.96*sigma)
        ci_high = pred + 1.96*sigma
        return int(round(pred)), int(round(ci_low)), int(round(ci_high))

    # ØªÙ‚Ø¯ÙŠØ± Ù…Ø¨Ø³Ù‘Ø·
    if len(y) >= 2:
        growth = y[-1] - y[-2]
        pred = int(round(y[-1] + growth))
        return pred, None, None

    return None, None, None

# Ù†Ø­Ø³Ø¨ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ù†Ø·Ø§Ù‚ Ù…Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ø®ØªØ§Ø± (Ø¨Ø¯ÙˆÙ† ØªÙ‚ÙŠÙŠØ¯ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹Ø› Ù…Ø¹ Ø¨Ù‚Ø§Ø¡ ØªÙ‚ÙŠÙŠØ¯ Ø§Ù„Ø´Ù‡Ø± = Ø§Ù„ÙƒÙ„ Ù„ÙƒÙŠ ÙŠÙƒÙˆÙ† Ø´Ù‡Ø±ÙŠ Ø´Ø§Ù…Ù„)
df_for_forecast = df_scope.copy()
pred_next, pred_ci_low, pred_ci_high = calc_forecast(df_for_forecast)

# Ø¨Ø·Ø§Ù‚Ø© KPI Ù„Ù„ØªÙ†Ø¨Ø¤ (Ø³Ø·Ø± Ù…Ø³ØªÙ‚Ù„ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ù€KPI Ø§Ù„Ø­Ø§Ù„ÙŠØ©)
c_pred = st.columns(1)[0]
with c_pred:
    if pred_next is not None:
        ci_html = f'<div class="badge" style="margin-top:.35rem;">Ù†Ø·Ø§Ù‚ ØªÙ‚Ø±ÙŠØ¨ÙŠ: {pred_ci_low} â€“ {pred_ci_high}</div>' if (pred_ci_low is not None and pred_ci_high is not None) else ""
        st.markdown(f"""<div class="kpi" style="margin-top:.5rem;">
            <div class="title">ØªÙˆÙ‚Ù‘Ø¹ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ù‚Ø§Ø¯Ù… (Ø­Ø³Ø¨ Ù†Ø·Ø§Ù‚ Ù…Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ø®ØªØ§Ø±)</div>
            <div class="value">{pred_next}</div>
            {ci_html}
        </div>""", unsafe_allow_html=True)
    else:
        st.markdown(f"""<div class="kpi" style="margin-top:.5rem;">
            <div class="title">ØªÙˆÙ‚Ù‘Ø¹ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ù‚Ø§Ø¯Ù…</div>
            <div class="value">â€”</div>
            <div class="badge" style="margin-top:.35rem;">Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ©</div>
        </div>""", unsafe_allow_html=True)

st.markdown("<hr>", unsafe_allow_html=True)

# =============== Ø§Ù„Ø±Ø³ÙˆÙ… ===============
st.markdown('<div class="glass">', unsafe_allow_html=True)
st.markdown("### Ø§Ù„Ø±Ø³ÙˆÙ…")
c1, c2 = st.columns(2)
with c1:
    if "Ø§Ù„Ù…Ù†Ø·Ù‚Ø©" in filtered.columns and not filtered.empty:
        reg_counts = filtered["Ø§Ù„Ù…Ù†Ø·Ù‚Ø©"].value_counts().reset_index()
        reg_counts.columns = ["Ø§Ù„Ù…Ù†Ø·Ù‚Ø©","Ø§Ù„Ø¹Ø¯Ø¯"]
        fig_reg = px.bar(reg_counts, x="Ø§Ù„Ù…Ù†Ø·Ù‚Ø©", y="Ø§Ù„Ø¹Ø¯Ø¯", title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ù†Ø·Ù‚Ø©", text="Ø§Ù„Ø¹Ø¯Ø¯")
        fig_reg.update_traces(textposition="outside")
        fig_reg.update_layout(template="plotly_dark", margin=dict(t=60,b=40,l=20,r=20))
        st.plotly_chart(fig_reg, use_container_width=True)
    else:
        st.info("Ù„Ø§ ØªØªÙˆÙØ± Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù†Ø§Ø·Ù‚ Ø¶Ù…Ù† Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ù…Ø­Ø¯Ø¯.")
with c2:
    if "Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø©" in filtered.columns and not filtered.empty:
        tcounts = filtered["Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø©"].value_counts()
        fig_type = px.pie(names=tcounts.index, values=tcounts.values, title="Ù†Ø³Ø¨Ø© Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª", hole=0.35)
        fig_type.update_traces(textposition="inside", textinfo="percent+label")
        fig_type.update_layout(template="plotly_dark", margin=dict(t=60,b=40,l=20,r=20))
        st.plotly_chart(fig_type, use_container_width=True)
    else:
        st.info("Ù„Ø§ ØªØªÙˆÙØ± Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø¶Ù…Ù† Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ù…Ø­Ø¯Ø¯.")
if "Ø§Ù„Ø´Ø±ÙƒØ©" in filtered.columns and not filtered.empty:
    comp_counts = filtered["Ø§Ù„Ø´Ø±ÙƒØ©"].value_counts().reset_index()
    comp_counts.columns = ["Ø§Ù„Ø´Ø±ÙƒØ©","Ø§Ù„Ø¹Ø¯Ø¯"]
    fig_comp = px.bar(comp_counts, x="Ø§Ù„Ø´Ø±ÙƒØ©", y="Ø§Ù„Ø¹Ø¯Ø¯", title="Ø¹Ø¯Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø´Ø±ÙƒØ©", text="Ø§Ù„Ø¹Ø¯Ø¯")
    fig_comp.update_traces(textposition="outside")
    fig_comp.update_layout(template="plotly_dark", margin=dict(t=60,b=40,l=20,r=20))
    st.plotly_chart(fig_comp, use_container_width=True)
st.markdown('</div>', unsafe_allow_html=True)

# =============== ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø­Ø³Ø¨ Ù…Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (3 Pies) ===============
st.markdown('<div class="glass" style="margin-top:1rem;">', unsafe_allow_html=True)
st.markdown("### Ù†Ø³Ø¨Ø© Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø­Ø³Ø¨ Ù…Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø®Ø¯Ù…Ø©")

agent_col = "Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (Ù…Ù„Ù)" if "Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (Ù…Ù„Ù)" in df_scope.columns else ("Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø©" if "Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø©" in df_scope.columns else None)

if agent_col:
    col_total, col_oct, col_week = st.columns(3)

    # --- 1) Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ (Ø­Ø³Ø¨ Ø§Ù„ØªØµÙÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ©) ---
    with col_total:
        if not filtered.empty:
            ac_total = filtered[agent_col].value_counts()
            if not ac_total.empty:
                names_total = ac_total.index.map(provider_to_ar) if agent_col == "Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (Ù…Ù„Ù)" else ac_total.index
                fig_agents_total = px.pie(
                    names=names_total, values=ac_total.values,
                    title="Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù†Ø³Ø¨Ø© Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª (Ø­Ø³Ø¨ Ø§Ù„ØªØµÙÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ©)", hole=0.35
                )
                fig_agents_total.update_traces(textposition="inside", textinfo="percent+label")
                fig_agents_total.update_layout(template="plotly_dark", margin=dict(t=60,b=40,l=20,r=20))
                st.plotly_chart(fig_agents_total, use_container_width=True)
            else:
                st.info("Ù„Ø§ ØªØªÙˆÙØ± Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù…Ù‚Ø¯Ù‘Ù…ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø© Ø¶Ù…Ù† Ø§Ù„ØªØµÙÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ©.")
        else:
            st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØµÙÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ©.")

    # --- 2) Ø´Ù‡Ø± Oct (ÙŠØ­ØªØ±Ù… Ø§Ø®ØªÙŠØ§Ø± Ù…Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø®Ø¯Ù…Ø©ØŒ Ù„Ø§ ÙŠØªØ£Ø«Ø± Ø¨Ù…Ø±Ø´Ø­ Ø§Ù„Ø´Ù‡Ø±/Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹) ---
    with col_oct:
        df_oct_scope = df_scope[df_scope["Ø§Ù„Ø´Ù‡Ø±"] == "Oct"].copy() if "Ø§Ù„Ø´Ù‡Ø±" in df_scope.columns else pd.DataFrame()
        if not df_oct_scope.empty:
            ac_oct = df_oct_scope[agent_col].value_counts()
            if not ac_oct.empty:
                names_oct = ac_oct.index.map(provider_to_ar) if agent_col == "Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (Ù…Ù„Ù)" else ac_oct.index
                fig_agents_oct = px.pie(
                    names=names_oct, values=ac_oct.values,
                    title="Ù†Ø³Ø¨Ø© Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª â€” Ø´Ù‡Ø± Ø£ÙƒØªÙˆØ¨Ø± (Ø¨Ù†ÙØ³ Ù†Ø·Ø§Ù‚ Ù…Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø®Ø¯Ù…Ø©)", hole=0.35
                )
                fig_agents_oct.update_traces(textposition="inside", textinfo="percent+label")
                fig_agents_oct.update_layout(template="plotly_dark", margin=dict(t=60,b=40,l=20,r=20))
                st.plotly_chart(fig_agents_oct, use_container_width=True)
            else:
                st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø´Ù‡Ø± Oct Ù„Ù†ÙØ³ Ù†Ø·Ø§Ù‚ Ù…Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø®Ø¯Ù…Ø©.")
        else:
            st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø³Ø¬Ù„Ø§Øª Ù„Ø´Ù‡Ø± Oct ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù†Ø·Ø§Ù‚.")

    # --- 3) Ø¢Ø®Ø± Ø£Ø³Ø¨ÙˆØ¹ (Ø£Ø­Ø¯Ø« WeekStart) Ø¶Ù…Ù† Ù†ÙØ³ Ù†Ø·Ø§Ù‚ Ù…Ù‚Ø¯Ù‘Ù… Ø§Ù„Ø®Ø¯Ù…Ø© ---
    with col_week:
        if "WeekStart" in df_scope.columns and not df_scope.dropna(subset=["WeekStart"]).empty:
            latest_ws = pd.to_datetime(df_scope["WeekStart"]).max()
            df_last_week = df_scope[pd.to_datetime(df_scope["WeekStart"]) == latest_ws].copy()
            if not df_last_week.empty:
                ac_week = df_last_week[agent_col].value_counts()
                names_week = ac_week.index.map(provider_to_ar) if agent_col == "Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (Ù…Ù„Ù)" else ac_week.index
                # Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ø¶Ø­ Ù…Ø¹ Ù†Ø·Ø§Ù‚ Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹
                we = pd.to_datetime(df_last_week["WeekEnd"].iloc[0]) if "WeekEnd" in df_last_week.columns else latest_ws + pd.Timedelta(days=4)
                week_title = f"Ù†Ø³Ø¨Ø© Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª â€” Ø¢Ø®Ø± Ø£Ø³Ø¨ÙˆØ¹ ({latest_ws.strftime('%b %d')}â€“{we.strftime('%b %d')})"
                fig_agents_week = px.pie(
                    names=names_week, values=ac_week.values,
                    title=week_title, hole=0.35
                )
                fig_agents_week.update_traces(textposition="inside", textinfo="percent+label")
                fig_agents_week.update_layout(template="plotly_dark", margin=dict(t=60,b=40,l=20,r=20))
                st.plotly_chart(fig_agents_week, use_container_width=True)
            else:
                st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø¢Ø®Ø± Ø£Ø³Ø¨ÙˆØ¹ Ø¯Ø§Ø®Ù„ Ù‡Ø°Ø§ Ø§Ù„Ù†Ø·Ø§Ù‚.")
        else:
            st.info("Ù„Ø§ ÙŠØªÙˆÙØ± Ø¹Ù…ÙˆØ¯ WeekStart/WeekEnd Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¢Ø®Ø± Ø£Ø³Ø¨ÙˆØ¹.")
else:
    st.info("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ Ù„Ù…Ù‚Ø¯Ù‘Ù…ÙŠ Ø§Ù„Ø®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©.")
st.markdown('</div>', unsafe_allow_html=True)

# =============== (Ø¥Ø¶Ø§ÙØ© Ø¬Ø¯ÙŠØ¯Ø©) Visual: Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ù„Ù„Ø´Ù‡Ø± Ø§Ù„Ù‚Ø§Ø¯Ù… ===============
st.markdown('<div class="glass" style="margin-top:1rem;">', unsafe_allow_html=True)
st.markdown("### Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ù„Ù„Ø´Ù‡Ø± Ø§Ù„Ù‚Ø§Ø¯Ù…")
MONTHS_12 = ["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"]

def next_month_label(curr: str) -> str:
    if curr not in MONTHS_12:
        return curr
    i = MONTHS_12.index(curr)
    return MONTHS_12[(i + 1) % 12]

def forecast_figure(df_month_scope: pd.DataFrame):
    if df_month_scope is None or df_month_scope.empty or "Ø§Ù„Ø´Ù‡Ø±" not in df_month_scope.columns:
        return None

    # Ù†Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø´Ù‡Ø± ÙƒÙ…Ø§ ÙÙŠ MONTH_ORDER Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© (Aug, Sep, Oct)
    month_totals = df_month_scope["Ø§Ù„Ø´Ù‡Ø±"].value_counts().reindex(MONTH_ORDER).dropna()
    if len(month_totals) < 1:
        return None

    # x Ø§Ù„ÙØ¹Ù„ÙŠØ© = Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø´Ù‡Ø± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙØ¹Ù„ÙŠÙ‹Ø§ Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨
    x_labels_actual = month_totals.index.tolist()            # Ù…Ø«Ø§Ù„: ['Aug','Sep','Oct']
    x_idx = np.arange(len(x_labels_actual)).reshape(-1, 1)   # 0,1,2 â€¦
    y_val = month_totals.values.astype(float)

    # Ø§Ø³Ù… Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ù‚Ø§Ø¯Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ (Ø¨Ø¯ÙˆÙ† modulo)
    next_label = next_month_label(x_labels_actual[-1])

    fig = go.Figure()

    # Ø§Ù„Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„ÙØ¹Ù„ÙŠ
    fig.add_trace(go.Scatter(
        x=x_labels_actual, y=y_val, mode="lines+markers", name="ÙØ¹Ù„ÙŠ",
        line=dict(width=3), marker=dict(size=8)
    ))

    # Ù†Ù…ÙˆØ°Ø¬ Ø®Ø·ÙŠ + Ù†Ù‚Ø·Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ + Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠ
    if _SK_OK and len(y_val) >= 2:
        from sklearn.linear_model import LinearRegression
        model = LinearRegression().fit(x_idx, y_val)
        next_x_numeric = np.array([[len(x_labels_actual)]])  # Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø¹Ø¯ Ø¢Ø®Ø± Ù†Ù‚Ø·Ø© ÙØ¹Ù„ÙŠØ©
        pred = float(model.predict(next_x_numeric)[0])

        resid = y_val - model.predict(x_idx)
        sigma = float(np.std(resid)) if len(resid) > 1 else 0.0
        ci_low = max(0.0, pred - 1.96 * sigma)
        ci_high = pred + 1.96 * sigma

        # Ø®Ø· Ø§Ù„Ø§ØªØ¬Ø§Ù‡: Ù…Ù† Ø£ÙˆÙ„ Ø´Ù‡Ø± ÙØ¹Ù„ÙŠ Ø¥Ù„Ù‰ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹
        line_x_full_num = np.arange(0, len(x_labels_actual) + 1)
        line_x_full_lbl = x_labels_actual + [next_label]
        line_y_full = model.predict(line_x_full_num.reshape(-1, 1))

        fig.add_trace(go.Scatter(
            x=line_x_full_lbl, y=line_y_full, mode="lines", name="Ø§ØªØ¬Ø§Ù‡",
            line=dict(dash="dot", width=2)
        ))
        # Ù†Ù‚Ø·Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ **Nov** (Ø£Ùˆ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„ØªØ§Ù„ÙŠ Ø§Ù„ÙØ¹Ù„ÙŠ)
        fig.add_trace(go.Scatter(
            x=[next_label], y=[pred], mode="markers+text", name="ØªÙˆÙ‚Ø¹ Ø§Ù„Ø´Ù‡Ø± Ø§Ù„Ù‚Ø§Ø¯Ù…",
            marker=dict(size=12, symbol="diamond"),
            text=[f"{int(round(pred))}"], textposition="top center"
        ))
        # Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠ Ø¹Ù„Ù‰ Ù†ÙØ³ Ø§Ù„ØªØµÙ†ÙŠÙ (Nov)
        fig.add_trace(go.Scatter(
            x=[next_label, next_label], y=[ci_low, ci_high], mode="lines", name="Ù†Ø·Ø§Ù‚ ØªÙ‚Ø±ÙŠØ¨ÙŠ",
            line=dict(color="rgba(164,220,255,.6)", width=8)
        ))
        # Ù†Ø«Ø¨Øª ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ø­ÙˆØ± Ø§Ù„Ø³ÙŠÙ†ÙŠ Ù„Ø¹Ø±Ø¶ Nov Ø¨Ø¹Ø¯ Oct
        fig.update_layout(
            xaxis=dict(categoryorder="array", categoryarray=line_x_full_lbl)
        )
    else:
        # Ø¨Ø¯ÙˆÙ† Sklearn: Ù†Ø¹Ø±Ø¶ Ø§Ù„ÙØ¹Ù„ÙŠ ÙÙ‚Ø· + Ù†Ù‚Ø·Ø© ØªÙ‚Ø¯ÙŠØ± Ù…Ø¨Ø³Ù‘Ø·Ø© Ø¥Ù† ØªÙˆÙØ±Øª Ø´Ù‡Ø±Ø§Ù†
        if len(y_val) >= 2:
            growth = y_val[-1] - y_val[-2]
            pred = int(round(y_val[-1] + growth))
            fig.add_trace(go.Scatter(
                x=[next_label], y=[pred], mode="markers+text", name="ØªÙˆÙ‚Ø¹ Ù…Ø¨Ø³Ù‘Ø·",
                marker=dict(size=12, symbol="diamond"),
                text=[str(pred)], textposition="top center"
            ))
            fig.update_layout(
                xaxis=dict(categoryorder="array", categoryarray=x_labels_actual + [next_label])
            )

    fig.update_layout(
        title="Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø´Ù‡Ø±ÙŠ + Ø§Ù„ØªÙˆÙ‚Ø¹ Ø§Ù„Ù‚Ø§Ø¯Ù…",
        template="plotly_dark", paper_bgcolor="rgba(0,0,0,0)",
        margin=dict(t=60, b=40, l=20, r=20),
        yaxis_title="Ø¹Ø¯Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª", xaxis_title="Ø§Ù„Ø´Ù‡Ø±"
    )
    return fig


fig_pred = forecast_figure(df_for_forecast)
if fig_pred is not None:
    st.plotly_chart(fig_pred, use_container_width=True)
else:
    st.info("Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ù„Ø¹Ø±Ø¶ Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„ØªÙ†Ø¨Ø¤.")

st.markdown('</div>', unsafe_allow_html=True)

# =============== Ø®Ø±ÙŠØ·Ø© (Ù…Ø¯Ù†/Ù…Ù†Ø§Ø·Ù‚) ===============
st.markdown('<div class="glass" style="margin-top:1rem;">', unsafe_allow_html=True)
st.markdown("### Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©/Ø§Ù„Ù…Ù†Ø·Ù‚Ø©")
CITY_LATLON = {
    "Ø§Ù„Ø±ÙŠØ§Ø¶": (24.7136, 46.6753), "Ø¬Ø¯Ø©": (21.4858, 39.1925), "Ù…ÙƒØ©": (21.3891, 39.8579),
    "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©": (24.5247, 39.5692), "Ø§Ù„Ø¯Ù…Ø§Ù…": (26.3927, 49.9777), "Ø§Ù„Ø®Ø¨Ø±": (26.2794, 50.2083),
    "Ø§Ù„Ø·Ø§Ø¦Ù": (21.2703, 40.4158), "Ø£Ø¨Ù‡Ø§": (18.2465, 42.5117), "Ø­Ø§Ø¦Ù„": (27.5114, 41.7208),
    "ØªØ¨ÙˆÙƒ": (28.3838, 36.5662), "Ø¬Ø§Ø²Ø§Ù†": (16.8892, 42.5700)
}
REGION_LATLON = {
    "Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø´Ø±Ù‚ÙŠØ©": (26.5, 49.8), "Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø±ÙŠØ§Ø¶": (24.7, 46.7), "Ù…Ù†Ø·Ù‚Ø© Ù…ÙƒØ©": (21.4, 40.7),
    "Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©": (24.6, 39.6), "Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù‚ØµÙŠÙ…": (26.3, 43.96), "Ù…Ù†Ø·Ù‚Ø© ØªØ¨ÙˆÙƒ": (28.4, 36.6),
    "Ù…Ù†Ø·Ù‚Ø© Ø­Ø§Ø¦Ù„": (27.5, 41.7), "Ù…Ù†Ø·Ù‚Ø© Ø¬Ø§Ø²Ø§Ù†": (16.9, 42.6), "Ù…Ù†Ø·Ù‚Ø© Ù†Ø¬Ø±Ø§Ù†": (17.6, 44.4),
    "Ù…Ù†Ø·Ù‚Ø© Ø¹Ø³ÙŠØ±": (18.2, 42.5), "Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø¬ÙˆÙ": (29.97, 40.2), "Ø§Ù„Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø´Ù…Ø§Ù„ÙŠØ©": (30.0, 41.0),
    "Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø¨Ø§Ø­Ø©": (20.0, 41.45), "Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø·Ø§Ø¦Ù": (21.27, 40.42)
}
def build_map_df(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty: return pd.DataFrame(columns=["label","lat","lon","count"])
    rows = []
    city_col = "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©" if "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©" in df.columns else ("Ø§Ù„Ù…Ø¯ÙŠÙ†Ù‡" if "Ø§Ù„Ù…Ø¯ÙŠÙ†Ù‡" in df.columns else None)
    if city_col:
        for name, n in df[city_col].value_counts().items():
            nm = str(name).strip()
            if nm in CITY_LATLON:
                lat, lon = CITY_LATLON[nm]
                rows.append({"label": nm, "lat": lat, "lon": lon, "count": int(n)})
    if not rows and "Ø§Ù„Ù…Ù†Ø·Ù‚Ø©" in df.columns:
        for name, n in df["Ø§Ù„Ù…Ù†Ø·Ù‚Ø©"].value_counts().items():
            nm = str(name).strip()
            if nm in REGION_LATLON:
                lat, lon = REGION_LATLON[nm]
                rows.append({"label": nm, "lat": lat, "lon": lon, "count": int(n)})
    return pd.DataFrame(rows)

map_df = build_map_df(filtered)
if not map_df.empty:
    fig_map = px.scatter_mapbox(
        map_df, lat="lat", lon="lon", size="count", color="count",
        hover_name="label", hover_data={"lat":False,"lon":False,"count":True},
        size_max=45, zoom=4.2, height=520, title="Ø®Ø±ÙŠØ·Ø© ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª"
    )
    fig_map.update_layout(mapbox_style="carto-darkmatter", paper_bgcolor="rgba(0,0,0,0)",
                          margin=dict(t=60,b=20,l=10,r=10), template="plotly_dark")
    st.plotly_chart(fig_map, use_container_width=True)
else:
    st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø¯Ù†/Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø¶Ù…Ù† Ø§Ù„Ù…Ø¯Ù‰ Ø§Ù„Ø­Ø§Ù„ÙŠ.")
st.markdown('</div>', unsafe_allow_html=True)

# =============== Word Cloud â€” Ø§Ù„Ø®Ø¯Ù…Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ù‡ ===============
st.markdown('<div class="glass" style="margin-top:1rem;">', unsafe_allow_html=True)
st.markdown("### â˜ï¸ Ø³Ø­Ø§Ø¨Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª â€” Ø§Ù„Ø®Ø¯Ù…Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ù‡")

def find_arabic_font():
    # Ø§Ø¨Ø­Ø« Ø¹Ù† Ø®Ø· Ø¹Ø±Ø¨ÙŠ Ù…Ù†Ø§Ø³Ø¨
    candidates = [
        os.path.join(ASSETS_DIR, "fonts", "Amiri-Regular.ttf"),
        os.path.join(ASSETS_DIR, "fonts", "Cairo-Regular.ttf"),
        os.path.join(ASSETS_DIR, "fonts", "NotoNaskhArabic-Regular.ttf"),
        "../fonts/NotoNaskhArabic-Regular.ttf",
        "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
        "/System/Library/Fonts/Supplemental/Arial Unicode.ttf",
        "arial.ttf"
    ]
    for fp in candidates:
        if os.path.isfile(fp):
            return fp
    return None

ARABIC_STOPWORDS = set("""
ÙÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù‰ Ø¥Ù„Ù‰ Ù…Ù† Ø¹Ù† Ù…Ø¹ Ù„Ø¯Ù‰ Ù„Ø¯ÙŠ Ø¹Ù†Ø¯ Ø«Ù… Ø£Ùˆ Ø£Ù… Ø£Ù† Ø¥Ù† ÙƒØ§Ù† ÙƒØ§Ù†Øª ÙŠÙƒÙˆÙ† ØªÙƒÙˆÙ† ØªÙ… ØªÙ…Ù‘ ØªÙ…ÙÙ‘ ØªÙ…Ù‘Ù Ù‚Ø¯ Ù„Ù‚Ø¯ Ø­ÙŠØ« Ø§Ù„Ø°ÙŠ Ø§Ù„ØªÙŠ Ø§Ù„Ø°ÙŠÙ† Ø§Ù„Ù„Ø°ÙŠ Ø§Ù„Ù„ØªÙŠ Ù‡Ø°Ø§ Ù‡Ø°Ù‡ Ù‡Ù†Ø§Ùƒ Ù‡Ù†Ø§ Ø¬Ø¯Ø§ Ø¬Ø¯Ø§Ù‹ ÙÙ‚Ø· Ø¨Ø´ÙƒÙ„ Ø¨Ø´ÙƒÙ„Ù Ø£ÙƒØ«Ø± Ø£Ù‚Ù„ Ø£ÙƒØ«Ø±Ù Ø£Ù‚Ù„Ù‘Ù ÙƒÙ„ ÙƒØ§ÙØ© Ø¬Ù…ÙŠØ¹ Ø¨Ø¹Ø¶ Ø£ÙŠ Ø§ÙŠ Ø´ÙŠØ¡ Ø´Ø¦ Ø´ÙŠØ¦ Ø´ÙŠØ§Ù‹ Ø´ÙŠØ¦Ø§
Ø®Ø¯Ù…Ø© Ø®Ø¯Ù…Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ù‡ Ø·Ù„Ø¨ Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø´Ø±ÙƒØ© Ø´Ø±ÙƒØ§Øª Ø±Ù‚Ù… Ù†ÙˆØ¹
""".split())

def normalize_text_ar(s: str) -> str:
    if not isinstance(s, str): s = str(s)
    s = s.strip()
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ù…ÙˆØ² ÙˆØ§Ù„Ø£Ø±Ù‚Ø§Ù…
    s = re.sub(r"[^\u0600-\u06FF\s]", " ", s)  # ÙÙ‚Ø· Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ù…Ø³Ø§ÙØ©
    s = re.sub(r"\s+", " ", s)
    return s

def build_wordcloud_from_column(df: pd.DataFrame, colname: str):
    if colname not in df.columns or df[colname].dropna().empty:
        return None
    # Ù†Øµ Ø¹Ø±Ø¨ÙŠ Ù…Ù‡ÙŠØ£
    words = []
    for t in df[colname].dropna().astype(str):
        t = normalize_text_ar(t)
        for w in t.split():
            if w and (w not in ARABIC_STOPWORDS):
                words.append(w)
    if not words:
        return None
    text = " ".join(words)

    # Ø¯Ø¹Ù… Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ÙƒÙŠÙ„ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§ØªØ¬Ø§Ù‡ RTL Ø¥Ù† ØªÙˆÙØ±Øª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª
    if AR_SUPPORT:
        try:
            reshaped = arabic_reshaper.reshape(text)
            display_text = get_display(reshaped)
        except Exception:
            display_text = text
    else:
        display_text = text

    font_path = find_arabic_font()

    wc = WordCloud(
        width=1200, height=520,
        background_color="white",
        max_words=300,
        collocations=True,
        prefer_horizontal=0.95,
        font_path=font_path
    ).generate(display_text)

    fig = plt.figure(figsize=(12, 5.2))
    plt.imshow(wc, interpolation="bilinear")
    plt.axis("off")
    plt.tight_layout()
    return fig

wc_fig = build_wordcloud_from_column(filtered, "Ø§Ù„Ø®Ø¯Ù…Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ù‡")
if wc_fig is not None:
    st.pyplot(wc_fig, use_container_width=True)
else:
    st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø­Ø§Ø¨Ø© ÙƒÙ„Ù…Ø§Øª Ù…Ù† Ø¹Ù…ÙˆØ¯ (Ø§Ù„Ø®Ø¯Ù…Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ù‡).")
st.markdown('</div>', unsafe_allow_html=True)

# =============== Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªÙØ§ØµÙŠÙ„ + Ø§Ù„Ø¨Ø­Ø« ===============
st.markdown('<div class="glass" style="margin-top:1rem;">', unsafe_allow_html=True)
st.markdown("### Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ")
cols_base = ['Ø§Ù„Ø´Ù‡Ø±','Ø§Ù„ØªØ§Ø±ÙŠØ®','Ø§Ù„ØªØ§Ø±ÙŠØ®/Date','ÙˆØ³Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹','Ø±Ù‚Ù… Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹',
             'Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„','Ø§Ù„Ù…Ù†Ø·Ù‚Ø©','Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©','Ø§Ù„Ø´Ø±ÙƒØ©','Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø©','Ø§Ù„Ø®Ø¯Ù…Ù‡ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ù‡','Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (Ù…Ù„Ù)']
show_cols = [c for c in cols_base if c in filtered.columns]
q = st.text_input("Ø§Ø¨Ø­Ø« Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¬Ø¯ÙˆÙ„ (Ø§Ù„Ø§Ø³Ù…/Ø§Ù„Ø´Ø±ÙƒØ©/Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©/Ø§Ù„Ù†ÙˆØ¹/Ø§Ù„Ø®Ø¯Ù…Ø©...)", "")
table_df = filtered.copy()
if q.strip() and show_cols:
    ql = q.strip().lower()
    mask = np.zeros(len(table_df), dtype=bool)
    for c in show_cols:
        s = table_df[c].astype(str).str.lower()
        mask |= s.str.contains(ql, na=False)
    table_df = table_df[mask]
if show_cols:
    # ØªØ±Ø¬Ù…Ø© Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ù„Ù„Ø¹Ø±Ø¶
    if "Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (Ù…Ù„Ù)" in table_df.columns:
        table_df["Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (Ù…Ù„Ù)"] = table_df["Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø© (Ù…Ù„Ù)"].map(provider_to_ar)
    st.dataframe(table_df[show_cols].reset_index(drop=True), use_container_width=True, height=460)
st.markdown('</div>', unsafe_allow_html=True)

# =============== Ù…Ù„Ø®Øµ Ø°ÙƒÙŠ Ù…Ø®ØªØµØ± ===============
st.markdown('<div class="glass" style="margin-top:1rem;">', unsafe_allow_html=True)
st.markdown("### ğŸ¤– Ù…Ù„Ø®Ù‘Øµ Ø°ÙƒÙŠ")
def quick_summary(df: pd.DataFrame) -> str:
    if df.empty: return "Ù„Ø§ ØªØªÙˆÙØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø¶Ù…Ù† Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ù…Ø­Ø¯Ø¯."
    parts = [f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª: **{len(df)}**."]
    if "Ø§Ù„Ù…Ù†Ø·Ù‚Ø©" in df.columns and not df["Ø§Ù„Ù…Ù†Ø·Ù‚Ø©"].value_counts().empty:
        parts.append(f"Ø§Ù„Ø£ÙƒØ«Ø± Ù†Ø´Ø§Ø·Ù‹Ø§: **{df['Ø§Ù„Ù…Ù†Ø·Ù‚Ø©'].value_counts().idxmax()}**.")
    if "Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø©" in df.columns and not df["Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø©"].value_counts().empty:
        parts.append(f"Ø£Ø´ÙŠØ¹ Ù†ÙˆØ¹: **{df['Ù†ÙˆØ¹ Ø§Ù„Ø®Ø¯Ù…Ø©'].value_counts().idxmax()}**.")
    if "Ø§Ù„Ø´Ø±ÙƒØ©" in df.columns and not df["Ø§Ù„Ø´Ø±ÙƒØ©"].value_counts().empty:
        parts.append(f"Ø§Ù„Ø´Ø±ÙƒØ© Ø§Ù„Ø£Ø¨Ø±Ø²: **{df['Ø§Ù„Ø´Ø±ÙƒØ©'].value_counts().idxmax()}**.")
    return " ".join(parts)
st.write(quick_summary(filtered))
st.markdown('</div>', unsafe_allow_html=True)
